# Plan de D√©veloppement Final - ThirdShop Text Analyzer
## Classification et Extraction de Donn√©es Produit (Version Consolid√©e)

**Date :** 4 octobre 2025  
**Version :** 1.0 Final (fusion des plans A et BIS)  
**Objectif :** Syst√®me production-ready pour cat√©goriser les pages web (produit vs non-produit) et extraire des donn√©es structur√©es avec normalisation rigoureuse

---

## üìä Table des mati√®res

1. [Vision et contexte](#vision-et-contexte)
2. [KPI et m√©triques de succ√®s](#kpi-et-m√©triques-de-succ√®s)
3. [API publique](#api-publique)
4. [Architecture technique](#architecture-technique)
5. [Sp√©cifications fonctionnelles](#sp√©cifications-fonctionnelles)
6. [Roadmap et jalons](#roadmap-et-jalons)
7. [Risques et mitigations](#risques-et-mitigations)
8. [Livrables](#livrables)
9. [Stack technique](#stack-technique)

---

## Vision et contexte

### Objectif global
Exploiter des documents HTML pour :
1. **Classifier** automatiquement les pages produit vs non-produit (F1 ‚â• 0.90)
2. **Extraire** des attributs cl√©s avec normalisation rigoureuse (prix, devise, r√©f√©rence, dimensions, poids, etc.)
3. **Fournir** des explications et des scores de confiance pour chaque d√©cision

### Approche technique
- **Multi-source fusion** : Combiner JSON-LD, microdata, Open Graph, heuristiques textuelles avec r√©solution de conflits
- **Feature engineering riche** : Features structurelles, textuelles et s√©mantiques pour classification explicable
- **Normalisation stricte** : Unit√©s SI, ISO 4217, formats standardis√©s avec tra√ßabilit√©
- **Performance optimis√©e** : Target ‚â•50 pages/s avec I/O parall√®le
- **Priorit√© FR** : Patterns et stopwords fran√ßais, extensible multi-langues

### Analyse de l'existant ‚úÖ

**Points forts :**
- ‚úÖ Gestion d'erreurs avec type `Result<T>` uniforme
- ‚úÖ Code modulaire (src/text/, src/stats/, src/math/)
- ‚úÖ 75 tests unitaires (100% de r√©ussite)
- ‚úÖ Documentation compl√®te dans `/documentations`
- ‚úÖ Normalisation HTML avec 5 strat√©gies
- ‚úÖ Analyse textuelle (TF, IDF, TF-IDF, co-occurrence, PCA)

**Ce qui manque :**
- ‚ùå Parser DOM structur√©
- ‚ùå Extraction m√©tadonn√©es e-commerce (Schema.org, Open Graph, JSON-LD)
- ‚ùå Classification automatique des pages
- ‚ùå Normalisation d'unit√©s (SI, ISO 4217)
- ‚ùå Pipeline unifi√© extraction + classification
- ‚ùå CLI d'analyse en lot

---

## KPI et m√©triques de succ√®s

### Classification (Produit vs Non-Produit)

| M√©trique | Sprint 2 (MVP) | Sprint 4 (Optimis√©) | Plan Final |
|----------|----------------|---------------------|------------|
| **F1-Score** | ‚â• 0.87 | ‚â• 0.92 | **‚â• 0.90** ‚úì |
| **Pr√©cision** | ‚â• 0.85 | ‚â• 0.90 | **‚â• 0.88** ‚úì |
| **Rappel** | ‚â• 0.90 | ‚â• 0.95 | **‚â• 0.92** ‚úì |
| **Confiance moyenne** | ‚â• 0.70 | ‚â• 0.80 | **‚â• 0.75** ‚úì |
| **AUPRC** | - | - | **‚â• 0.92** ‚úì |

### Extraction de donn√©es

| Attribut | Objectif | Mesure |
|----------|----------|--------|
| **Prix + Devise** | **‚â• 98%** | Exactitude ¬±0.01 unit√©, ISO 4217 |
| **R√©f√©rence/SKU** | **‚â• 95%** | Exact-match (case-insensitive) |
| **Nom produit** | **‚â• 90%** | Pr√©sence + coh√©rence |
| **Marque** | **‚â• 85%** | Exact-match |
| **Poids** | **‚â• 90%** | Normalisation en grammes ¬±1% |
| **Dimensions** | **‚â• 90%** | Normalisation en millim√®tres ¬±1% |
| **Images produit** | **‚â• 85%** | Comptage + pertinence |
| **JSON-LD Product** | **‚â• 95%** | D√©tection quand pr√©sent |

### Performance

| M√©trique | Objectif |
|----------|----------|
| **Throughput** | **‚â• 50 pages/s** |
| **Latence par page** | < 20ms (en moyenne) |
| **Batch 100 pages** | < 5s (I/O parall√®le) |
| **M√©moire** | < 500MB stable |
| **CPU** | ‚â§ 80% sur 4 cores |

---

## API publique

### Fonctions principales

```typescript
/**
 * Classifie une page HTML comme produit ou non-produit
 * @returns Score, label, features extraites, raisons explicatives
 */
export function isProductPage(
  html: string,
  opts?: ClassificationOptions
): Result<{
  score: number;           // 0-10
  label: boolean;          // true = produit
  confidence: number;      // 0-1
  features: PageFeatures;
  reasons: string[];       // Explications lisibles
}>;

/**
 * Extrait toutes les informations produit disponibles
 * @returns Donn√©es produit normalis√©es avec confiance et evidence
 */
export function extractProductInfo(
  html: string,
  opts?: ExtractionOptions
): Result<{
  product: ProductInfo;
  confidence: number;             // 0-1 global
  evidence: ExtractionEvidence[]; // Tra√ßabilit√© par source
}>;

/**
 * Analyse compl√®te : classification + extraction + analyse textuelle
 * Point d'entr√©e principal du pipeline
 */
export function analyzePage(
  html: string,
  opts?: AnalysisOptions
): Result<AnalysisResult>;

/**
 * Parse HTML et extrait m√©tadonn√©es structur√©es
 */
export function parseDom(
  html: string
): Result<{
  document: DomLike;
  jsonLd: any[];
  microdata: any[];
  openGraph: Record<string, string>;
  metadata: PageMetadata;
}>;

/**
 * Analyse batch avec parall√©lisation
 */
export async function analyzePages(
  htmlPages: Array<{ id: string; html: string }>,
  opts?: AnalysisOptions
): Promise<Result<Map<string, AnalysisResult>>>;

/**
 * Analyse d'un dossier complet
 */
export async function analyzeDirectory(
  dirpath: string,
  pattern?: string,
  opts?: AnalysisOptions
): Promise<Result<Map<string, AnalysisResult>>>;
```

### Types de donn√©es

```typescript
export interface ProductInfo {
  // Identifiants
  reference?: string;        // SKU, EAN, r√©f√©rence interne
  sku?: string;
  ean?: string;
  gtin13?: string;
  gtin14?: string;
  
  // Informations de base
  name?: string;
  brand?: string;
  model?: string;
  category?: string;
  description?: string;
  
  // Prix (normalis√©)
  price?: {
    amount: number;          // En centimes (EUR) ou cents (USD)
    currency: string;        // ISO 4217 (EUR, USD, GBP, etc.)
    originalValue: string;   // Valeur originale extraite
    confidence: number;      // 0-1
  };
  
  // Caract√©ristiques physiques (normalis√©es SI)
  weight?: {
    value: number;          // En grammes
    unit: 'g';              // Toujours g apr√®s normalisation
    originalValue: string;
    originalUnit: string;
  };
  
  dimensions?: {
    length?: number;        // En millim√®tres
    width?: number;
    height?: number;
    diameter?: number;
    unit: 'mm';            // Toujours mm apr√®s normalisation
    originalValue: string;
  };
  
  // Capacit√©s √©lectriques (normalis√©es SI)
  battery?: {
    capacity: number;       // En mAh
    voltage?: number;       // En V
    power?: number;         // En W
  };
  
  // Disponibilit√©
  availability?: 'in_stock' | 'out_of_stock' | 'preorder' | 'discontinued' | 'unknown';
  stockQuantity?: number;
  
  // Images
  images?: Array<{
    url: string;
    alt?: string;
    width?: number;
    height?: number;
    isPrimary: boolean;
  }>;
  
  // M√©tadonn√©es
  condition?: 'new' | 'used' | 'refurbished' | 'unknown';
  warranty?: string;
  color?: string;
  size?: string;
  material?: string;
  
  // Tra√ßabilit√© extraction
  extractionMethods: Array<'jsonld' | 'microdata' | 'opengraph' | 'pattern' | 'context' | 'semantic'>;
  confidence: number;      // 0-1 confiance globale
}

export interface ExtractionEvidence {
  field: string;           // Nom du champ (ex: "price")
  value: any;              // Valeur extraite
  source: 'jsonld' | 'microdata' | 'opengraph' | 'pattern' | 'context' | 'semantic';
  confidence: number;      // 0-1
  location?: string;       // XPath ou s√©lecteur CSS
  rawText?: string;        // Texte original extrait
}

export interface PageFeatures {
  // Features structurelles HTML
  structural: {
    hasSchemaOrgProduct: boolean;
    hasOpenGraphProduct: boolean;
    hasJsonLdProduct: boolean;
    hasAddToCartButton: boolean;
    hasBuyButton: boolean;
    hasProductImages: boolean;
    hasRatings: boolean;
    hasPriceDisplay: boolean;
    imageCount: number;
    imageHighResCount: number;      // ‚â• 300x300
    linkDensity: number;            // ratio liens/contenu
    tableCount: number;
    listCount: number;
    formCount: number;
  };
  
  // Features textuelles
  textual: {
    wordCount: number;
    digitDensity: number;           // ratio chiffres/mots
    ecommerceKeywordCount: number;  // "prix", "acheter", "panier", etc.
    productKeywordCount: number;    // "r√©f√©rence", "dimensions", etc.
    hasPrice: boolean;
    hasPriceLabel: boolean;         // "Prix", "Price", etc.
    hasReference: boolean;
    hasStock: boolean;
    hasShipping: boolean;
    hasWarranty: boolean;
    topTermsTfidf: Array<[string, number]>;
    language?: string;              // D√©tection langue
  };
  
  // Features s√©mantiques
  semantic: {
    hasSpecTable: boolean;          // Tableau de sp√©cifications
    hasFeatureList: boolean;        // Liste de caract√©ristiques
    hasProductDescription: boolean;
    hasProductTitle: boolean;
    contentStructureScore: number;  // 0-10
    mainContentDensity: number;     // Ratio contenu principal/total
  };
  
  // Scores agr√©g√©s
  scores: {
    structuralScore: number;    // 0-10
    textualScore: number;       // 0-10
    semanticScore: number;      // 0-10
    overallScore: number;       // 0-10 (pond√©r√©)
  };
}

export interface AnalysisResult {
  // Classification
  classification: {
    isProductPage: boolean;
    confidence: number;
    score: number;           // 0-10
    reasons: string[];       // Explications lisibles
    features: PageFeatures;
  };
  
  // Donn√©es produit (si page produit)
  productData?: ProductInfo;
  evidence?: ExtractionEvidence[];
  
  // Analyse textuelle
  textAnalysis: {
    wordCount: number;
    topTerms: Array<[string, number]>;
    keyPhrases: string[];
    language?: string;
  };
  
  // M√©tadonn√©es page
  metadata: {
    title?: string;
    description?: string;
    keywords?: string[];
    language?: string;
    canonical?: string;
  };
  
  // Statistiques traitement
  processingTime: number;
  stepsCompleted: string[];
  errors?: string[];
}
```

---

## Architecture technique

### Vue d'ensemble du pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      HTML INPUT                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 1: PARSING DOM & NORMALISATION                       ‚îÇ
‚îÇ  - Parse HTML (linkedom)                                     ‚îÇ
‚îÇ  - Extraction JSON-LD, microdata, Open Graph                 ‚îÇ
‚îÇ  - Normalisation HTML (WITH_METADATA)                        ‚îÇ
‚îÇ  - D√©tection contenu principal (densit√©, nav removal)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 2: FEATURE ENGINEERING                                ‚îÇ
‚îÇ  - Features structurelles (JSON-LD, boutons, forms)         ‚îÇ
‚îÇ  - Features textuelles (TF-IDF, keywords, digit density)    ‚îÇ
‚îÇ  - Features s√©mantiques (tables, lists, content structure)  ‚îÇ
‚îÇ  - Calcul scores pond√©r√©s                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 3: CLASSIFICATION                                     ‚îÇ
‚îÇ  - Scoring multi-crit√®res (structural √ó 0.5 + textual √ó 0.3 ‚îÇ
‚îÇ    + semantic √ó 0.2)                                         ‚îÇ
‚îÇ  - D√©cision: seuil calibr√© (d√©faut 5.0/10)                 ‚îÇ
‚îÇ  - G√©n√©ration raisons explicatives                          ‚îÇ
‚îÇ  - Calcul confiance bas√© sur distance au seuil             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ NON-PRODUIT ‚Üí R√©sultat minimal
                       ‚îÇ
                       ‚ñº PRODUIT
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 4: EXTRACTION MULTI-SOURCE                            ‚îÇ
‚îÇ  - Priorit√©: JSON-LD > microdata > OpenGraph > patterns     ‚îÇ
‚îÇ  - Normalisation unit√©s (SI, ISO 4217)                      ‚îÇ
‚îÇ  - Fusion avec r√©solution conflits                          ‚îÇ
‚îÇ  - Evidence tracking d√©taill√©                               ‚îÇ
‚îÇ  - Context-aware extraction (proximit√© textuelle)           ‚îÇ
‚îÇ  - Semantic extraction (tableaux specs, listes)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 5: ANALYSE TEXTUELLE (Optionnelle)                   ‚îÇ
‚îÇ  - TF-IDF top termes                                        ‚îÇ
‚îÇ  - Extraction key phrases                                   ‚îÇ
‚îÇ  - Co-occurrence analysis                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  R√âSULTAT ENRICHI                                            ‚îÇ
‚îÇ  - Classification + confiance + explications                 ‚îÇ
‚îÇ  - Donn√©es produit normalis√©es + evidence                    ‚îÇ
‚îÇ  - Analyse textuelle (top termes, keyphrases)               ‚îÇ
‚îÇ  - M√©tadonn√©es + statistiques traitement                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Organisation des modules

```
src/
‚îú‚îÄ‚îÄ html/                        # NOUVEAU - Parsing HTML
‚îÇ   ‚îú‚îÄ‚îÄ parser.ts               # Parser DOM (linkedom wrapper)
‚îÇ   ‚îú‚îÄ‚îÄ content_extractor.ts    # Extraction contenu principal
‚îÇ   ‚îú‚îÄ‚îÄ dom_utils.ts            # Utilitaires DOM (querySelector, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ parser_types.ts         # Types (DOMNode, ParseOptions)
‚îÇ   ‚îî‚îÄ‚îÄ parser_test.ts
‚îÇ
‚îú‚îÄ‚îÄ extraction/                  # NOUVEAU - Extraction donn√©es produit
‚îÇ   ‚îú‚îÄ‚îÄ product_extractor.ts   # Orchestration extraction principale
‚îÇ   ‚îú‚îÄ‚îÄ schema_parser.ts        # Schema.org, Open Graph, JSON-LD
‚îÇ   ‚îú‚îÄ‚îÄ pattern_matcher.ts      # Patterns regex (prix, ref, dimensions)
‚îÇ   ‚îú‚îÄ‚îÄ semantic_extractor.ts   # Extraction tableaux, listes specs
‚îÇ   ‚îú‚îÄ‚îÄ context_extractor.ts    # Extraction par proximit√© textuelle
‚îÇ   ‚îú‚îÄ‚îÄ normalizer.ts           # Normalisation unit√©s (SI, ISO 4217)
‚îÇ   ‚îú‚îÄ‚îÄ fusion.ts               # Fusion multi-source + r√©solution conflits
‚îÇ   ‚îú‚îÄ‚îÄ patterns.ts             # Biblioth√®que patterns FR/EN
‚îÇ   ‚îú‚îÄ‚îÄ extraction_types.ts     # Types (ProductInfo, Evidence, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ extraction_test.ts
‚îÇ
‚îú‚îÄ‚îÄ classification/              # NOUVEAU - Classification pages
‚îÇ   ‚îú‚îÄ‚îÄ features.ts             # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ rule_classifier.ts      # Classificateur bas√© sur r√®gles
‚îÇ   ‚îú‚îÄ‚îÄ scoring.ts              # Syst√®me de scoring d√©taill√©
‚îÇ   ‚îú‚îÄ‚îÄ ml_classifier.ts        # Classificateur ML (Sprint 4, optionnel)
‚îÇ   ‚îú‚îÄ‚îÄ calibration.ts          # Calibration seuils (AUPRC, F1)
‚îÇ   ‚îú‚îÄ‚îÄ classification_types.ts # Types (Features, ClassificationResult)
‚îÇ   ‚îî‚îÄ‚îÄ classification_test.ts
‚îÇ
‚îú‚îÄ‚îÄ pipeline/                    # NOUVEAU - Pipeline unifi√©
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.ts             # Pipeline principal
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.ts      # Traitement parall√®le batch
‚îÇ   ‚îú‚îÄ‚îÄ formatters.ts           # Export JSON, CSV, Markdown, texte
‚îÇ   ‚îú‚îÄ‚îÄ reporters.ts            # G√©n√©ration rapports m√©triques
‚îÇ   ‚îú‚îÄ‚îÄ analyzer_types.ts       # Types (AnalysisOptions, AnalysisResult)
‚îÇ   ‚îî‚îÄ‚îÄ analyzer_test.ts
‚îÇ
‚îú‚îÄ‚îÄ cli/                         # NOUVEAU - Interface CLI
‚îÇ   ‚îú‚îÄ‚îÄ analyze.ts              # Commande principale
‚îÇ   ‚îú‚îÄ‚îÄ commands.ts             # Sous-commandes (extract, classify, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ config.ts               # Configuration CLI
‚îÇ   ‚îî‚îÄ‚îÄ output.ts               # Formatage sortie console
‚îÇ
‚îú‚îÄ‚îÄ text/                        # EXISTANT - Modules texte (AM√âLIOR√â)
‚îÇ   ‚îú‚îÄ‚îÄ normalize.ts            # ‚úÖ D√©j√† impl√©ment√©
‚îÇ   ‚îú‚îÄ‚îÄ tokenize.ts             # ‚úÖ Am√©lior√© (digits, n-grams, stopwords FR)
‚îÇ   ‚îú‚îÄ‚îÄ tf.ts, idf.ts, tfidf.ts # ‚úÖ D√©j√† impl√©ment√©
‚îÇ   ‚îú‚îÄ‚îÄ cooccurrence.ts         # ‚úÖ D√©j√† impl√©ment√©
‚îÇ   ‚îî‚îÄ‚îÄ stopwords_fr.ts         # NOUVEAU - Liste stopwords fran√ßais
‚îÇ
‚îú‚îÄ‚îÄ stats/                       # EXISTANT - Statistiques
‚îÇ   ‚îî‚îÄ‚îÄ ...                     # ‚úÖ D√©j√† impl√©ment√©
‚îÇ
‚îú‚îÄ‚îÄ math/                        # EXISTANT - Matrices, alg√®bre
‚îÇ   ‚îî‚îÄ‚îÄ ...                     # ‚úÖ D√©j√† impl√©ment√©
‚îÇ
‚îî‚îÄ‚îÄ types/
    ‚îî‚îÄ‚îÄ result.ts               # ‚úÖ D√©j√† impl√©ment√©
```

---

## Sp√©cifications fonctionnelles

### 1. Parsing DOM et contenu principal

#### 1.1 Parser HTML structur√© (`src/html/parser.ts`)

**Objectif :** Wrapper robuste autour de linkedom pour Deno

**Fonctionnalit√©s :**
- Parse HTML en structure DOM navigable
- Support s√©lecteurs CSS complets
- Extraction JSON-LD, microdata, Open Graph
- Gestion entit√©s HTML et encodage
- Tol√©rance aux erreurs (HTML malform√©)

**API :**
```typescript
export function parseHtml(html: string, opts?: ParseOptions): Result<ParsedDocument>;
export function querySelector(root: DOMNode, selector: string): Result<DOMNode | null>;
export function querySelectorAll(root: DOMNode, selector: string): Result<DOMNode[]>;
export function extractJsonLd(document: DOMNode): Result<any[]>;
export function extractMicrodata(document: DOMNode): Result<any[]>;
export function extractOpenGraph(document: DOMNode): Result<Record<string, string>>;
```

#### 1.2 Extraction contenu principal (`src/html/content_extractor.ts`)

**Objectif :** Isoler le contenu principal pour am√©liorer features textuelles

**Heuristiques :**
- Calcul densit√© texte/liens par bloc
- Suppression navigation, header, footer, sidebar
- D√©tection sections r√©p√©titives (menus, ads)
- Score de pertinence par n≈ìud DOM

**API :**
```typescript
export function extractMainContent(document: DOMNode): Result<{
  mainContent: string;
  mainContentNode: DOMNode;
  contentDensity: number;
  removedNodes: string[]; // Types de n≈ìuds supprim√©s
}>;
```

### 2. Feature Engineering

#### 2.1 Features structurelles (`src/classification/features.ts`)

**Extraction automatique depuis DOM :**
```typescript
structural: {
  hasSchemaOrgProduct: boolean;          // itemtype="Product"
  hasOpenGraphProduct: boolean;          // og:type="product"
  hasJsonLdProduct: boolean;             // @type="Product"
  hasAddToCartButton: boolean;           // Bouton "Ajouter au panier"
  hasBuyButton: boolean;                 // Bouton "Acheter"
  hasProductImages: boolean;             // Images ‚â• 300x300
  hasRatings: boolean;                   // √âtoiles, avis
  hasPriceDisplay: boolean;              // Affichage prix stylis√©
  imageCount: number;
  imageHighResCount: number;
  linkDensity: number;                   // < 0.3 typique pour produits
  tableCount: number;
  listCount: number;
  formCount: number;
}
```

**Scoring :** `structuralScore = Œ£(feature √ó weight) / maxScore √ó 10`

#### 2.2 Features textuelles (`src/classification/features.ts`)

**Extraction depuis texte normalis√© :**
```typescript
textual: {
  wordCount: number;
  digitDensity: number;                  // Produits ont souvent beaucoup de chiffres
  ecommerceKeywordCount: number;         // "prix", "acheter", "livraison", etc.
  productKeywordCount: number;           // "r√©f√©rence", "dimensions", "poids"
  hasPrice: boolean;
  hasPriceLabel: boolean;
  hasReference: boolean;
  hasStock: boolean;
  hasShipping: boolean;
  hasWarranty: boolean;
  topTermsTfidf: Array<[string, number]>;
  language?: string;
}
```

**Mots-cl√©s e-commerce FR/EN :**
```typescript
export const ECOMMERCE_KEYWORDS = [
  // FR
  'prix', 'acheter', 'ajouter', 'panier', 'commander', 'livraison',
  'stock', 'disponible', 'garantie', 'retour', 'remboursement',
  // EN
  'price', 'buy', 'add', 'cart', 'order', 'shipping', 'delivery',
  'stock', 'available', 'warranty', 'return', 'refund'
];
```

**Scoring :** `textualScore = f(keywordDensity, digitDensity, price presence, ...)`

#### 2.3 Features s√©mantiques (`src/classification/features.ts`)

**Analyse structure contenu :**
```typescript
semantic: {
  hasSpecTable: boolean;                 // <table> avec "Caract√©ristiques"
  hasFeatureList: boolean;               // <ul>/<dl> avec specs
  hasProductDescription: boolean;        // Bloc description d√©taill√©e
  hasProductTitle: boolean;              // <h1> type produit
  contentStructureScore: number;         // 0-10 qualit√© structure
  mainContentDensity: number;            // Ratio contenu principal/total
}
```

### 3. Classification

#### 3.1 Classificateur bas√© sur r√®gles (`src/classification/rule_classifier.ts`)

**Formule de scoring :**
```typescript
overallScore = 
  (structuralScore √ó 0.5) +
  (textualScore √ó 0.3) +
  (semanticScore √ó 0.2)

isProductPage = overallScore >= threshold (d√©faut: 5.0)

confidence = sigmoid((overallScore - threshold) / 2.0)
```

**G√©n√©ration raisons explicatives :**
```typescript
reasons = [
  "‚úì JSON-LD Product d√©tect√©",
  "‚úì Prix trouv√©: 120.00 EUR",
  "‚úì R√©f√©rence produit: 23572714",
  "‚úì Tableau de sp√©cifications pr√©sent",
  "‚ö† Pas de bouton 'Ajouter au panier'",
  "‚ö† Faible densit√© d'images"
]
```

#### 3.2 Calibration des seuils (`src/classification/calibration.ts`)

**M√©thode :**
1. Annoter dataset de validation (produit/non-produit)
2. Calculer scores sur tout le dataset
3. G√©n√©rer courbe Precision-Recall
4. S√©lectionner seuil maximisant F1 ou AUPRC
5. Valider sur test set s√©par√©

**API :**
```typescript
export function calibrateThreshold(
  examples: LabeledExample[],
  metric: 'f1' | 'auprc'
): Result<{
  optimalThreshold: number;
  f1Score: number;
  precision: number;
  recall: number;
  auprc: number;
}>;
```

### 4. Extraction multi-source

#### 4.1 Extraction JSON-LD / Microdata / Open Graph (`src/extraction/schema_parser.ts`)

**Priorit√© :** JSON-LD > Microdata > Open Graph

**Standards support√©s :**

**JSON-LD (priorit√© 1) :**
```json
{
  "@context": "https://schema.org/",
  "@type": "Product",
  "name": "Compresseur air conditionn√© PEUGEOT 307",
  "sku": "23572714",
  "brand": { "@type": "Brand", "name": "PEUGEOT" },
  "offers": {
    "@type": "Offer",
    "price": "120.00",
    "priceCurrency": "EUR",
    "availability": "https://schema.org/InStock"
  },
  "weight": { "@type": "QuantitativeValue", "value": "2.5", "unitCode": "KGM" },
  "image": "https://example.com/product.jpg"
}
```

**Microdata (priorit√© 2) :**
```html
<div itemscope itemtype="https://schema.org/Product">
  <span itemprop="name">Compresseur</span>
  <span itemprop="price">120.00</span>
  <span itemprop="priceCurrency">EUR</span>
</div>
```

**Open Graph (priorit√© 3) :**
```html
<meta property="og:type" content="product">
<meta property="product:price:amount" content="120.00">
<meta property="product:price:currency" content="EUR">
```

#### 4.2 Extraction par patterns regex (`src/extraction/pattern_matcher.ts`)

**Biblioth√®que patterns FR/EN :**
```typescript
export const PATTERNS = {
  // Prix (multi-formats)
  PRICE_EUR_SYMBOL: /(\d+(?:[.,]\d{2})?)\s*‚Ç¨/g,
  PRICE_EUR_CODE: /(\d+(?:[.,]\d{2})?)\s*EUR/gi,
  PRICE_LABELED_FR: /prix[\s:]*(\d+[.,]\d{2})/gi,
  PRICE_LABELED_EN: /price[\s:]*(\d+[.,]\d{2})/gi,
  PRICE_USD: /\$\s*(\d+(?:[.,]\d{2})?)/g,
  
  // R√©f√©rence/SKU (multi-formats)
  REF_LABELED_FR: /r√©f(?:√©rence)?[\s:.]*([A-Z0-9-]{4,20})/gi,
  REF_LABELED_EN: /ref(?:erence)?[\s:.]*([A-Z0-9-]{4,20})/gi,
  SKU_LABELED: /SKU[\s:.]*([A-Z0-9-]{4,20})/gi,
  EAN: /EAN[\s:.]*(\d{13})/gi,
  GTIN: /GTIN[\s:.]*(\d{8,14})/gi,
  
  // Poids (normalisation vers grammes)
  WEIGHT_KG: /(\d+(?:[.,]\d+)?)\s*kg/gi,
  WEIGHT_G: /(\d+)\s*g(?:rammes?)?/gi,
  WEIGHT_LABELED_FR: /poids[\s:]*(\d+(?:[.,]\d+)?)\s*(kg|g)/gi,
  WEIGHT_LABELED_EN: /weight[\s:]*(\d+(?:[.,]\d+)?)\s*(kg|g)/gi,
  
  // Dimensions (normalisation vers mm)
  DIMENSIONS_3D: /(\d+)\s*[x√ó]\s*(\d+)\s*[x√ó]\s*(\d+)\s*(mm|cm|m)/gi,
  DIMENSIONS_2D: /(\d+)\s*[x√ó]\s*(\d+)\s*(mm|cm|m)/gi,
  LENGTH_LABELED: /longueur[\s:]*(\d+)\s*(mm|cm|m)/gi,
  WIDTH_LABELED: /largeur[\s:]*(\d+)\s*(mm|cm|m)/gi,
  HEIGHT_LABELED: /hauteur[\s:]*(\d+)\s*(mm|cm|m)/gi,
  
  // Stock/Disponibilit√©
  IN_STOCK_FR: /en\s+stock|disponible/gi,
  OUT_OF_STOCK_FR: /rupture|indisponible|√©puis√©/gi,
  IN_STOCK_EN: /in\s+stock|available/gi,
  OUT_OF_STOCK_EN: /out\s+of\s+stock|unavailable|sold\s+out/gi,
};
```

#### 4.3 Normalisation d'unit√©s (`src/extraction/normalizer.ts`)

**Objectif :** Unit√©s SI + ISO 4217 pour comparabilit√©

**R√®gles de normalisation :**

```typescript
// Prix ‚Üí centimes + ISO 4217
"120.00 ‚Ç¨" ‚Üí { amount: 12000, currency: "EUR" }
"$99.99"   ‚Üí { amount: 9999, currency: "USD" }
"45,50 EUR" ‚Üí { amount: 4550, currency: "EUR" }

// Poids ‚Üí grammes
"2.5 kg"   ‚Üí { value: 2500, unit: "g" }
"500 g"    ‚Üí { value: 500, unit: "g" }
"1.2kg"    ‚Üí { value: 1200, unit: "g" }

// Dimensions ‚Üí millim√®tres
"30 x 20 x 10 cm" ‚Üí { length: 300, width: 200, height: 100, unit: "mm" }
"1.5 m"           ‚Üí { value: 1500, unit: "mm" }
"250 mm"          ‚Üí { value: 250, unit: "mm" }

// Capacit√© batterie ‚Üí mAh
"3000 mAh" ‚Üí { capacity: 3000, unit: "mAh" }
"3 Ah"     ‚Üí { capacity: 3000, unit: "mAh" }
```

**API :**
```typescript
export function normalizePrice(value: string, currency?: string): Result<Money>;
export function normalizeWeight(value: string | number, unit: string): Result<Weight>;
export function normalizeDimension(value: string | number, unit: string): Result<number>; // mm
export function normalizeBatteryCapacity(value: string | number, unit: string): Result<number>; // mAh
```

#### 4.4 Extraction context-aware (`src/extraction/context_extractor.ts`)

**Objectif :** Trouver valeurs par proximit√© textuelle avec mots-cl√©s

**M√©thode :**
1. Tokenizer le texte avec positions
2. Trouver occurrences de mots-cl√©s ("Prix", "R√©f√©rence", etc.)
3. Chercher patterns dans fen√™tre de N tokens autour
4. Scorer par distance au mot-cl√©

**Exemple :**
```
Texte: "... R√©f√©rence fabricant : 23572714. Ce compresseur ..."
       ‚Üë keyword         ‚Üë value (distance: 2 tokens)
```

**API :**
```typescript
export function extractByContext(
  text: string,
  keywords: string[],
  pattern: RegExp,
  windowSize?: number  // d√©faut: 10 tokens
): Result<Array<{
  value: string;
  keyword: string;
  distance: number;
  confidence: number;
}>>;
```

#### 4.5 Extraction s√©mantique (`src/extraction/semantic_extractor.ts`)

**Objectif :** Extraire depuis tableaux HTML et listes structur√©es

**Tableaux de sp√©cifications :**
```html
<table>
  <tr><td>R√©f√©rence</td><td>23572714</td></tr>
  <tr><td>Poids</td><td>2.5 kg</td></tr>
  <tr><td>Dimensions</td><td>30 x 20 x 10 cm</td></tr>
</table>
```

**Listes de caract√©ristiques :**
```html
<dl>
  <dt>SKU</dt><dd>ABC123</dd>
  <dt>Marque</dt><dd>PEUGEOT</dd>
</dl>
```

**API :**
```typescript
export function extractFromTable(
  tableNode: DOMNode,
  keyColumn?: number,
  valueColumn?: number
): Result<Record<string, string>>;

export function extractFromList(
  listNode: DOMNode,
  listType: 'dl' | 'ul'
): Result<Record<string, string>>;
```

#### 4.6 Fusion multi-source (`src/extraction/fusion.ts`)

**Objectif :** R√©soudre conflits entre sources et maximiser confiance

**Strat√©gie de fusion :**
1. **Pond√©ration par source :**
   - JSON-LD : poids 1.0
   - Microdata : poids 0.8
   - Open Graph : poids 0.6
   - Pattern + context : poids 0.4
   - Pattern seul : poids 0.3

2. **R√©solution conflits :**
   - Si valeurs identiques ‚Üí confiance maximale
   - Si valeurs proches (¬±1%) ‚Üí moyenne pond√©r√©e
   - Si valeurs divergentes ‚Üí prendre source prioritaire

3. **Evidence tracking :**
   - Enregistrer toutes les sources pour chaque champ
   - Fournir tra√ßabilit√© compl√®te

**API :**
```typescript
export function mergeProductData(
  sources: Array<{
    data: Partial<ProductInfo>;
    source: ExtractionMethod;
    weight: number;
  }>
): Result<{
  merged: ProductInfo;
  evidence: ExtractionEvidence[];
  conflicts: Array<{
    field: string;
    values: any[];
    resolution: string;
  }>;
}>;
```

### 5. Pipeline unifi√©

#### 5.1 Orchestration principale (`src/pipeline/analyzer.ts`)

**Impl√©mentation du pipeline :**

```typescript
export function analyzePage(
  html: string,
  opts: AnalysisOptions = {}
): Result<AnalysisResult> {
  const startTime = performance.now();
  const stepsCompleted: string[] = [];
  const errors: string[] = [];
  
  // √âTAPE 1: Parsing DOM
  const [parseErr, parsed] = parseDom(html);
  if (parseErr) return fail(parseErr);
  stepsCompleted.push('parsing');
  
  // √âTAPE 2: Normalisation HTML
  const [normErr, normalized] = normalizeHtml(html, {
    strategy: opts.normalizationStrategy ?? 'WITH_METADATA'
  });
  if (normErr) return fail(normErr);
  stepsCompleted.push('normalization');
  
  // √âTAPE 3: Extraction contenu principal
  const [contentErr, mainContent] = extractMainContent(parsed.document);
  if (contentErr) errors.push(`Content extraction: ${contentErr.message}`);
  stepsCompleted.push('content_extraction');
  
  // √âTAPE 4: Feature engineering
  const [featErr, features] = extractFeatures(html, normalized, mainContent);
  if (featErr) return fail(featErr);
  stepsCompleted.push('features');
  
  // √âTAPE 5: Classification
  let classification: ClassificationResult;
  if (!opts.skipClassification) {
    const [classErr, classResult] = classifyPage(features, opts.classifierRules);
    if (classErr) return fail(classErr);
    classification = classResult;
    stepsCompleted.push('classification');
  }
  
  // √âTAPE 6: Extraction produit (si page produit)
  let productData: ProductInfo | undefined;
  let evidence: ExtractionEvidence[] | undefined;
  
  if (opts.skipClassification || classification.isProductPage) {
    const [extractErr, extracted] = extractProductInfo(html, parsed, opts.extractionOptions);
    if (extractErr) {
      errors.push(`Extraction: ${extractErr.message}`);
    } else {
      productData = extracted.product;
      evidence = extracted.evidence;
      stepsCompleted.push('extraction');
    }
  }
  
  // √âTAPE 7: Analyse textuelle TF-IDF (optionnelle)
  let topTerms: Array<[string, number]> = [];
  if (opts.computeTfidf ?? true) {
    const [tfErr, tf] = termFrequency(normalized.text, { asRelative: true });
    if (!tfErr) {
      topTerms = Object.entries(tf)
        .sort((a, b) => b[1] - a[1])
        .slice(0, opts.topTermsCount ?? 20);
      stepsCompleted.push('tfidf');
    }
  }
  
  // √âTAPE 8: Assemblage r√©sultat
  const result: AnalysisResult = {
    classification: {
      isProductPage: classification?.isProductPage ?? false,
      confidence: classification?.confidence ?? 0,
      score: classification?.score ?? 0,
      reasons: classification?.reasons ?? [],
      features
    },
    productData,
    evidence,
    textAnalysis: {
      wordCount: normalized.text.split(/\s+/).length,
      topTerms,
      keyPhrases: [],
      language: normalized.metadata?.language
    },
    metadata: normalized.metadata ?? {},
    processingTime: performance.now() - startTime,
    stepsCompleted,
    errors: errors.length > 0 ? errors : undefined
  };
  
  return ok(result);
}
```

#### 5.2 Traitement batch parall√®le (`src/pipeline/batch_processor.ts`)

**Objectif :** Analyser 100+ pages en parall√®le avec contr√¥le concurrence

**API :**
```typescript
export async function analyzePagesBatch(
  pages: Array<{ id: string; html: string }>,
  opts?: AnalysisOptions & { concurrency?: number }
): Promise<Result<Map<string, AnalysisResult>>> {
  const concurrency = opts?.concurrency ?? 10;
  const results = new Map<string, AnalysisResult>();
  
  // Traitement par chunks parall√®les
  for (let i = 0; i < pages.length; i += concurrency) {
    const chunk = pages.slice(i, i + concurrency);
    const promises = chunk.map(async ({ id, html }) => {
      const [err, result] = analyzePage(html, opts);
      if (!err) results.set(id, result);
      return { id, err, result };
    });
    
    await Promise.all(promises);
  }
  
  return ok(results);
}
```

#### 5.3 Formatters (`src/pipeline/formatters.ts`)

**Formats de sortie support√©s :**

```typescript
// JSON (d√©taill√© ou compact)
export function formatAsJson(result: AnalysisResult, pretty?: boolean): string;

// CSV (pour batch analysis)
export function formatAsCsv(results: Map<string, AnalysisResult>): string;

// Markdown (rapport lisible)
export function formatAsMarkdown(result: AnalysisResult): string;

// Texte (console-friendly)
export function formatAsText(result: AnalysisResult): string;

// Rapport comparatif
export function generateComparisonReport(
  results: Map<string, AnalysisResult>
): string;
```

**Exemple sortie Markdown :**
```markdown
# Analyse: pieceoccasion-1.html

## Classification
- **Type:** Page Produit ‚úì
- **Confiance:** 0.89
- **Score:** 7.8/10

### Raisons
‚úì JSON-LD Product d√©tect√©
‚úì Prix trouv√©: 120.00 EUR
‚úì R√©f√©rence produit: 23572714
‚úì Tableau de sp√©cifications pr√©sent
‚ö† Pas de bouton 'Ajouter au panier'

## Donn√©es Produit
- **Nom:** Compresseur air conditionn√© PEUGEOT 307
- **Prix:** 120.00 EUR (confiance: 0.95)
- **R√©f√©rence:** 23572714
- **Marque:** PEUGEOT
- **Disponibilit√©:** En stock

## Statistiques
- Temps de traitement: 12.5ms
- √âtapes compl√©t√©es: 7/7
```

### 6. CLI

#### 6.1 Interface ligne de commande (`cli/analyze.ts`)

**Commandes principales :**

```bash
# Analyser un fichier
deno run -A cli/analyze.ts --file dataset/pieceoccasion-1.html --format json

# Analyser un dossier
deno run -A cli/analyze.ts --dir dataset/ --pattern "*.html" --format csv --out results.csv

# Classification seulement (plus rapide)
deno run -A cli/analyze.ts --dir dataset/ --classify-only --format json

# Extraction seulement (pour pages d√©j√† identifi√©es comme produits)
deno run -A cli/analyze.ts --dir dataset/ --extract-only --format json

# Avec options avanc√©es
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --format json \
  --out results.json \
  --concurrency 20 \
  --threshold 5.5 \
  --tfidf \
  --top-terms 30

# G√©n√©ration rapport m√©triques (avec ground truth)
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --ground-truth labels.json \
  --metrics-report
```

**Options disponibles :**
```typescript
interface CliOptions {
  // Input
  file?: string;
  dir?: string;
  pattern?: string;
  
  // Output
  out?: string;
  format: 'json' | 'csv' | 'markdown' | 'text';
  pretty?: boolean;
  
  // Processing
  concurrency?: number;
  classifyOnly?: boolean;
  extractOnly?: boolean;
  skipClassification?: boolean;
  
  // Classification
  threshold?: number;
  structuralWeight?: number;
  textualWeight?: number;
  semanticWeight?: number;
  
  // Extraction
  enableJsonLd?: boolean;
  enableMicrodata?: boolean;
  enableOpenGraph?: boolean;
  enablePatterns?: boolean;
  
  // Text analysis
  tfidf?: boolean;
  topTerms?: number;
  
  // Evaluation
  groundTruth?: string;
  metricsReport?: boolean;
  
  // Debug
  verbose?: boolean;
  includeFeatures?: boolean;
  includeEvidence?: boolean;
}
```

---

## Roadmap et jalons

### Sprint 0 : Pr√©paration (1 jour)

**Objectifs :**
- ‚úÖ Validation plan final
- ‚úÖ Setup d√©pendances (linkedom)
- ‚úÖ Cr√©ation structure de dossiers
- ‚úÖ Types de base

**Livrables :**
- `src/html/parser_types.ts`
- `src/extraction/extraction_types.ts`
- `src/classification/classification_types.ts`
- `src/pipeline/analyzer_types.ts`
- `deno.json` avec d√©pendances

**Crit√®res de succ√®s :**
- [ ] Projet compile sans erreurs
- [ ] linkedom importable
- [ ] Types valid√©s

---

### Sprint 1 : Parsing & Extraction de base (3 jours)

**Objectifs :**
- ‚úÖ Parser DOM + linkedom wrapper
- ‚úÖ Extraction JSON-LD, microdata, Open Graph
- ‚úÖ Patterns regex (prix, r√©f√©rence)
- ‚úÖ Normalisation unit√©s (SI, ISO 4217)
- ‚úÖ Tests sur dataset

**Livrables :**
- `src/html/parser.ts`
- `src/html/dom_utils.ts`
- `src/extraction/schema_parser.ts`
- `src/extraction/pattern_matcher.ts`
- `src/extraction/normalizer.ts`
- `src/extraction/patterns.ts`
- Tests unitaires (‚â•20 tests)

**Crit√®res de succ√®s :**
- [ ] Prix extrait et normalis√© sur 3/3 pages produit (¬±0.01)
- [ ] R√©f√©rence extraite sur 3/3 pages produit (exact-match)
- [ ] JSON-LD d√©tect√© correctement (100%)
- [ ] Normalisation EUR/USD/GBP fonctionnelle
- [ ] Normalisation kg/g/mm/cm fonctionnelle
- [ ] 0 erreur sur pages non-produit

---

### Sprint 2 : Classification compl√®te (3 jours)

**Objectifs :**
- ‚úÖ Feature engineering (structural, textual, semantic)
- ‚úÖ Content extractor (densit√©, nav removal)
- ‚úÖ Classificateur bas√© sur r√®gles
- ‚úÖ Syst√®me de scoring d√©taill√©
- ‚úÖ G√©n√©ration raisons explicatives
- ‚úÖ Tests de classification

**Livrables :**
- `src/html/content_extractor.ts`
- `src/classification/features.ts`
- `src/classification/rule_classifier.ts`
- `src/classification/scoring.ts`
- `src/text/stopwords_fr.ts`
- Tests unitaires (‚â•25 tests)

**Crit√®res de succ√®s :**
- [ ] F1 ‚â• 0.90 sur dataset (6 fichiers)
- [ ] Pr√©cision ‚â• 0.88
- [ ] Rappel ‚â• 0.92
- [ ] Confiance moyenne ‚â• 0.75
- [ ] Aucun faux n√©gatif sur pages produit (rappel 100%)
- [ ] Raisons explicatives g√©n√©r√©es pour toutes les pages

---

### Sprint 3 : Pipeline & CLI (2 jours)

**Objectifs :**
- ‚úÖ Pipeline unifi√©
- ‚úÖ Extraction multi-source compl√®te (context, semantic)
- ‚úÖ Fusion avec r√©solution conflits
- ‚úÖ Batch processor parall√®le
- ‚úÖ Formatters (JSON, CSV, Markdown, texte)
- ‚úÖ CLI complet
- ‚úÖ Documentation utilisateur

**Livrables :**
- `src/extraction/context_extractor.ts`
- `src/extraction/semantic_extractor.ts`
- `src/extraction/fusion.ts`
- `src/extraction/product_extractor.ts` (orchestration)
- `src/pipeline/analyzer.ts`
- `src/pipeline/batch_processor.ts`
- `src/pipeline/formatters.ts`
- `cli/analyze.ts`
- `cli/commands.ts`
- `documentations/USER_GUIDE.md`
- Tests d'int√©gration (‚â•10 tests)

**Crit√®res de succ√®s :**
- [ ] Pipeline fonctionne sur tout le dataset (6/6)
- [ ] Batch 100 pages < 5s (target: 50+ pages/s)
- [ ] CLI produit JSON/CSV/Markdown valides
- [ ] Evidence tracking complet pour toutes extractions
- [ ] Fusion r√©sout correctement les conflits
- [ ] Documentation utilisateur compl√®te

---

### Sprint 4 : Am√©lioration & Production (3-5 jours, optionnel)

**Objectifs :**
- ‚úÖ Extraction avanc√©e (dimensions 3D, capacit√©s √©lectriques)
- ‚úÖ Calibration seuils (AUPRC, F1)
- ‚úÖ Classificateur ML (r√©gression logistique)
- ‚úÖ Benchmarks et m√©triques d√©taill√©es
- ‚úÖ Optimisation performance
- ‚úÖ Extension multi-langues (EN, ES)
- ‚úÖ Documentation compl√®te

**Livrables :**
- `src/classification/ml_classifier.ts`
- `src/classification/calibration.ts`
- `tests/benchmarks/classification_metrics.ts`
- `tests/benchmarks/extraction_precision.ts`
- `tools/dataset_annotator.ts`
- `tools/metrics_reporter.ts`
- `documentations/CLASSIFICATION_GUIDE.md`
- `documentations/EXTRACTION_GUIDE.md`
- `documentations/PATTERNS_REFERENCE.md`

**Crit√®res de succ√®s :**
- [ ] F1 ‚â• 0.95 avec ML
- [ ] AUPRC ‚â• 0.92
- [ ] Extraction dimensions 3D ‚â• 90%
- [ ] Extraction poids ‚â• 90%
- [ ] Throughput ‚â• 50 pages/s
- [ ] M√©moire < 500MB stable
- [ ] Documentation technique compl√®te

---

## Risques et mitigations

### Risque 1 : HTML h√©t√©rog√®ne / anti-scraping

**Impact :** √âchec parsing ou extraction incompl√®te  
**Probabilit√© :** Haute  
**Mitigations :**
- ‚úÖ Privil√©gier JSON-LD (standard structur√©)
- ‚úÖ Tol√©rance aux erreurs DOM (try/catch)
- ‚úÖ Fallback sur patterns regex si DOM √©choue
- ‚úÖ Content extractor pour isoler contenu principal
- ‚úÖ Tests sur HTML r√©els vari√©s

### Risque 2 : Formats prix/unit√©s vari√©s

**Impact :** Extraction incorrecte ou normalisation √©chou√©e  
**Probabilit√© :** Moyenne  
**Mitigations :**
- ‚úÖ Biblioth√®que exhaustive de patterns FR/EN
- ‚úÖ Normalisation stricte avec validation
- ‚úÖ Tests unitaires par format (EUR, USD, GBP, kg, g, cm, mm)
- ‚úÖ Evidence tracking pour debug
- ‚úÖ Logging des √©checs de normalisation

### Risque 3 : Performance DOM parsing

**Impact :** Latence > 50ms par page  
**Probabilit√© :** Moyenne  
**Mitigations :**
- ‚úÖ linkedom (l√©ger, performant)
- ‚úÖ Parse s√©lectif (limiter profondeur DOM)
- ‚úÖ Batch processing parall√®le (concurrence: 10-20)
- ‚úÖ Cache normalisation unit√©s
- ‚úÖ Profiling r√©gulier (Deno.bench)

### Risque 4 : Qualit√© dataset / annotations

**Impact :** M√©triques peu fiables, seuils mal calibr√©s  
**Probabilit√© :** Moyenne  
**Mitigations :**
- ‚úÖ Annotations multi-personnes avec accord inter-annotateurs
- ‚úÖ Validation set s√©par√© du test set
- ‚úÖ Mise √† jour continue du dataset
- ‚úÖ √âquilibrage classes (50/50 produit/non-produit)
- ‚úÖ Revue manuelle des erreurs de classification

### Risque 5 : Faux positifs (pages non-produit class√©es produit)

**Impact :** D√©gradation confiance utilisateurs  
**Probabilit√© :** Faible  
**Mitigations :**
- ‚úÖ Seuil conservateur (favoriser pr√©cision > rappel)
- ‚úÖ Poids √©lev√© pour features structurelles (JSON-LD)
- ‚úÖ Validation multi-crit√®res (prix + r√©f√©rence + images)
- ‚úÖ Score de confiance explicite dans r√©sultat

### Risque 6 : R√©gression lors des √©volutions

**Impact :** Baisse m√©triques apr√®s changement code  
**Probabilit√© :** Moyenne  
**Mitigations :**
- ‚úÖ Suite de tests compl√®te (‚â•100 tests)
- ‚úÖ Tests d'int√©gration sur dataset complet
- ‚úÖ CI/CD avec gate sur m√©triques minimales
- ‚úÖ Benchmarks automatiques avant/apr√®s

---

## Livrables

### Code

```
src/
‚îú‚îÄ‚îÄ html/
‚îÇ   ‚îú‚îÄ‚îÄ parser.ts
‚îÇ   ‚îú‚îÄ‚îÄ content_extractor.ts
‚îÇ   ‚îú‚îÄ‚îÄ dom_utils.ts
‚îÇ   ‚îú‚îÄ‚îÄ parser_types.ts
‚îÇ   ‚îî‚îÄ‚îÄ parser_test.ts
‚îÇ
‚îú‚îÄ‚îÄ extraction/
‚îÇ   ‚îú‚îÄ‚îÄ product_extractor.ts      # Orchestration
‚îÇ   ‚îú‚îÄ‚îÄ schema_parser.ts           # JSON-LD, microdata, OG
‚îÇ   ‚îú‚îÄ‚îÄ pattern_matcher.ts         # Regex patterns
‚îÇ   ‚îú‚îÄ‚îÄ semantic_extractor.ts      # Tables, listes
‚îÇ   ‚îú‚îÄ‚îÄ context_extractor.ts       # Proximit√© textuelle
‚îÇ   ‚îú‚îÄ‚îÄ normalizer.ts              # SI, ISO 4217
‚îÇ   ‚îú‚îÄ‚îÄ fusion.ts                  # Multi-source merge
‚îÇ   ‚îú‚îÄ‚îÄ patterns.ts                # Biblioth√®que patterns
‚îÇ   ‚îú‚îÄ‚îÄ extraction_types.ts
‚îÇ   ‚îî‚îÄ‚îÄ extraction_test.ts
‚îÇ
‚îú‚îÄ‚îÄ classification/
‚îÇ   ‚îú‚îÄ‚îÄ features.ts                # Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ rule_classifier.ts         # R√®gles pond√©r√©es
‚îÇ   ‚îú‚îÄ‚îÄ scoring.ts                 # Scoring d√©taill√©
‚îÇ   ‚îú‚îÄ‚îÄ ml_classifier.ts           # ML (Sprint 4)
‚îÇ   ‚îú‚îÄ‚îÄ calibration.ts             # Calibration seuils
‚îÇ   ‚îú‚îÄ‚îÄ classification_types.ts
‚îÇ   ‚îî‚îÄ‚îÄ classification_test.ts
‚îÇ
‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.ts                # Pipeline principal
‚îÇ   ‚îú‚îÄ‚îÄ batch_processor.ts         # Parall√©lisation
‚îÇ   ‚îú‚îÄ‚îÄ formatters.ts              # JSON, CSV, Markdown
‚îÇ   ‚îú‚îÄ‚îÄ reporters.ts               # Rapports m√©triques
‚îÇ   ‚îú‚îÄ‚îÄ analyzer_types.ts
‚îÇ   ‚îî‚îÄ‚îÄ analyzer_test.ts
‚îÇ
‚îú‚îÄ‚îÄ cli/
‚îÇ   ‚îú‚îÄ‚îÄ analyze.ts                 # CLI principal
‚îÇ   ‚îú‚îÄ‚îÄ commands.ts                # Sous-commandes
‚îÇ   ‚îú‚îÄ‚îÄ config.ts
‚îÇ   ‚îî‚îÄ‚îÄ output.ts
‚îÇ
‚îî‚îÄ‚îÄ text/ (am√©lior√©)
    ‚îú‚îÄ‚îÄ tokenize.ts                # + digits, n-grams
    ‚îî‚îÄ‚îÄ stopwords_fr.ts            # Nouveau
```

### Tests

```
tests/
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ full_pipeline_test.ts      # Pipeline bout-en-bout
‚îÇ   ‚îú‚îÄ‚îÄ dataset_analysis_test.ts   # Test sur dataset complet
‚îÇ   ‚îî‚îÄ‚îÄ regression_test.ts         # Non-r√©gression
‚îÇ
‚îî‚îÄ‚îÄ benchmarks/
    ‚îú‚îÄ‚îÄ classification_metrics.ts  # M√©triques classification
    ‚îú‚îÄ‚îÄ extraction_precision.ts    # M√©triques extraction
    ‚îî‚îÄ‚îÄ performance_bench.ts       # Benchmarks perf
```

### Documentation

```
documentations/
‚îú‚îÄ‚îÄ USER_GUIDE.md                  # Guide utilisateur CLI
‚îú‚îÄ‚îÄ API_REFERENCE.md               # Documentation API publique
‚îÇ
‚îú‚îÄ‚îÄ classification/
‚îÇ   ‚îú‚îÄ‚îÄ CLASSIFICATION_GUIDE.md    # Guide classification
‚îÇ   ‚îú‚îÄ‚îÄ FEATURES_REFERENCE.md      # D√©tail features
‚îÇ   ‚îî‚îÄ‚îÄ CALIBRATION_GUIDE.md       # Calibration seuils
‚îÇ
‚îú‚îÄ‚îÄ extraction/
‚îÇ   ‚îú‚îÄ‚îÄ EXTRACTION_GUIDE.md        # Guide extraction
‚îÇ   ‚îú‚îÄ‚îÄ PATTERNS_REFERENCE.md      # Catalogue patterns
‚îÇ   ‚îú‚îÄ‚îÄ SCHEMA_SUPPORT.md          # Standards support√©s
‚îÇ   ‚îî‚îÄ‚îÄ NORMALIZATION.md           # Normalisation unit√©s
‚îÇ
‚îî‚îÄ‚îÄ pipeline/
    ‚îú‚îÄ‚îÄ PIPELINE_GUIDE.md          # Architecture pipeline
    ‚îî‚îÄ‚îÄ PERFORMANCE_TUNING.md      # Optimisation perf
```

### Outils

```
tools/
‚îú‚îÄ‚îÄ dataset_annotator.ts           # Annotation assist√©e
‚îú‚îÄ‚îÄ metrics_reporter.ts            # G√©n√©ration rapports
‚îú‚îÄ‚îÄ calibration_tool.ts            # Calibration interactive
‚îî‚îÄ‚îÄ validation_dashboard.ts        # Dashboard m√©triques
```

### Datasets

```
dataset/
‚îú‚îÄ‚îÄ pieceoccasion-1.html          # ‚úÖ Existant
‚îú‚îÄ‚îÄ pieceoccasion-2.html          # ‚úÖ Existant
‚îú‚îÄ‚îÄ zero-motorcycles-1.html       # ‚úÖ Existant
‚îú‚îÄ‚îÄ google-1.html                 # ‚úÖ Existant
‚îú‚îÄ‚îÄ youtube-1.html                # ‚úÖ Existant
‚îú‚îÄ‚îÄ vehiculeselectriques-forum-1.html # ‚úÖ Existant
‚îú‚îÄ‚îÄ labels.json                   # NOUVEAU - Annotations
‚îî‚îÄ‚îÄ ground_truth.json             # NOUVEAU - Valeurs attendues
```

---

## Stack technique

### Runtime & Langage
- **Deno 1.x** avec TypeScript strict
- Modules natifs Deno (fs, path, testing)

### Parsing HTML
- **linkedom** - Parser DOM l√©ger pour Deno
- Support s√©lecteurs CSS complets
- Extraction JSON-LD, microdata, Open Graph

### Tests
- **Deno test** natif
- **@std/assert** pour assertions
- **Deno.bench** pour benchmarks perf

### Formats de sortie
- **JSON** (structur√©)
- **CSV** (batch analysis)
- **Markdown** (rapports lisibles)
- **Texte** (console)

### ML (Optionnel - Sprint 4)
- **R√©gression logistique from scratch** (pr√©f√©r√©)
- Alternative: TensorFlow.js ou ml-regression

### D√©pendances

```json
{
  "imports": {
    "@std/assert": "jsr:@std/assert@^1",
    "@std/path": "jsr:@std/path@^1",
    "@std/fs": "jsr:@std/fs@^1",
    "linkedom": "npm:linkedom@^0.16"
  }
}
```

---

## Commandes utiles

```bash
# Tests complets
deno test --allow-read

# Tests avec couverture
deno test --allow-read --coverage=coverage/

# Tests d'un module sp√©cifique
deno test --allow-read src/extraction/

# Benchmarks performance
deno bench --allow-read

# Analyse d'une page
deno run -A cli/analyze.ts --file dataset/pieceoccasion-1.html --format json

# Analyse batch du dataset
deno run -A cli/analyze.ts --dir dataset/ --format csv --out results.csv

# Classification uniquement (plus rapide)
deno run -A cli/analyze.ts --dir dataset/ --classify-only

# G√©n√©ration rapport m√©triques
deno run -A cli/analyze.ts --dir dataset/ --ground-truth dataset/labels.json --metrics-report

# Calibration seuils
deno run -A tools/calibration_tool.ts --dataset dataset/ --labels dataset/labels.json

# Format code
deno fmt

# Lint code
deno lint
```

---

## Prochaines √©tapes imm√©diates

### 1. Validation du plan ‚úÖ
- [x] Relecture du plan final
- [ ] Feedback et ajustements
- [ ] Validation des priorit√©s

### 2. Setup Sprint 0 (Jour 1)
- [ ] Cr√©er structure de dossiers compl√®te
- [ ] Ajouter linkedom dans `deno.json`
- [ ] Cr√©er fichiers de types (`*_types.ts`)
- [ ] Valider compilation

### 3. D√©marrage Sprint 1 (Jours 2-4)
- [ ] Impl√©menter `src/html/parser.ts` (wrapper linkedom)
- [ ] Impl√©menter `src/extraction/schema_parser.ts` (JSON-LD)
- [ ] Impl√©menter `src/extraction/patterns.ts` (regex prix EUR)
- [ ] Impl√©menter `src/extraction/normalizer.ts` (prix ‚Üí centimes)
- [ ] Tests sur `pieceoccasion-1.html`

### 4. Validation continue
- [ ] Tests unitaires √† chaque commit
- [ ] Validation m√©triques apr√®s chaque sprint
- [ ] Documentation √† jour

---

## Annexes

### A. Exemples de donn√©es extraites attendues

**pieceoccasion-1.html (Sprint 1) :**
```json
{
  "name": "Compresseur air conditionn√© pour PEUGEOT 307",
  "reference": "23572714",
  "brand": "PEUGEOT",
  "price": {
    "amount": 12000,
    "currency": "EUR",
    "originalValue": "120.00 ‚Ç¨",
    "confidence": 0.95
  },
  "condition": "used",
  "availability": "in_stock",
  "extractionMethods": ["jsonld", "opengraph", "pattern"],
  "confidence": 0.92
}
```

**pieceoccasion-1.html (Sprint 3, complet) :**
```json
{
  "name": "Compresseur air conditionn√© pour PEUGEOT 307",
  "reference": "23572714",
  "brand": "PEUGEOT",
  "model": "307",
  "category": "Pi√®ces d√©tach√©es",
  "price": {
    "amount": 12000,
    "currency": "EUR",
    "originalValue": "120.00 ‚Ç¨",
    "confidence": 0.95
  },
  "weight": {
    "value": 2500,
    "unit": "g",
    "originalValue": "2.5 kg",
    "originalUnit": "kg"
  },
  "availability": "in_stock",
  "condition": "used",
  "images": [
    {
      "url": "https://example.com/product.jpg",
      "width": 800,
      "height": 600,
      "isPrimary": true
    }
  ],
  "extractionMethods": ["jsonld", "opengraph", "pattern", "context", "semantic"],
  "confidence": 0.92
}
```

**R√©sultat analyse compl√®te :**
```json
{
  "classification": {
    "isProductPage": true,
    "confidence": 0.89,
    "score": 7.8,
    "reasons": [
      "‚úì JSON-LD Product d√©tect√©",
      "‚úì Prix trouv√©: 120.00 EUR",
      "‚úì R√©f√©rence produit: 23572714",
      "‚úì Tableau de sp√©cifications pr√©sent",
      "‚úì Images haute r√©solution: 3",
      "‚ö† Pas de bouton 'Ajouter au panier'"
    ],
    "features": { "..." }
  },
  "productData": { "..." },
  "evidence": [
    {
      "field": "price",
      "value": { "amount": 12000, "currency": "EUR" },
      "source": "jsonld",
      "confidence": 0.95,
      "location": "script[type='application/ld+json']"
    },
    {
      "field": "reference",
      "value": "23572714",
      "source": "opengraph",
      "confidence": 0.90,
      "location": "meta[property='product:retailer_item_id']"
    }
  ],
  "textAnalysis": {
    "wordCount": 487,
    "topTerms": [["compresseur", 0.08], ["peugeot", 0.06], ...],
    "language": "fr"
  },
  "metadata": {
    "title": "Compresseur air conditionn√© PEUGEOT 307 - PieceOccasion.fr",
    "language": "fr"
  },
  "processingTime": 12.5,
  "stepsCompleted": ["parsing", "normalization", "features", "classification", "extraction", "tfidf"]
}
```

### B. Exemples de commandes CLI

```bash
# Analyse simple
deno run -A cli/analyze.ts --file dataset/pieceoccasion-1.html

# Batch avec rapport Markdown
deno run -A cli/analyze.ts --dir dataset/ --format markdown --out report.md

# Export CSV pour analyse Excel
deno run -A cli/analyze.ts --dir dataset/ --format csv --out results.csv

# Avec options classification personnalis√©es
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --threshold 6.0 \
  --structural-weight 0.6 \
  --textual-weight 0.3 \
  --semantic-weight 0.1

# Mode debug complet
deno run -A cli/analyze.ts \
  --file dataset/pieceoccasion-1.html \
  --verbose \
  --include-features \
  --include-evidence \
  --format json \
  --pretty

# √âvaluation avec ground truth
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --ground-truth dataset/labels.json \
  --metrics-report \
  --out metrics.json
```

---

**Fin du plan de d√©veloppement final**

*Version consolid√©e - Pr√™t pour impl√©mentation*  
*Date: 4 octobre 2025*
