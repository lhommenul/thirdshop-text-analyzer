# Plan de DÃ©veloppement Final - ThirdShop Text Analyzer
## Classification et Extraction de DonnÃ©es Produit (Version ConsolidÃ©e)

**Date :** 4 octobre 2025  
**Version :** 1.0 Final (fusion des plans A et BIS)  
**Objectif :** SystÃ¨me production-ready pour catÃ©goriser les pages web (produit vs non-produit) et extraire des donnÃ©es structurÃ©es avec normalisation rigoureuse

---

## ğŸ“Š Table des matiÃ¨res

1. [Vision et contexte](#vision-et-contexte)
2. [KPI et mÃ©triques de succÃ¨s](#kpi-et-mÃ©triques-de-succÃ¨s)
3. [API publique](#api-publique)
4. [Architecture technique](#architecture-technique)
5. [SpÃ©cifications fonctionnelles](#spÃ©cifications-fonctionnelles)
6. [Roadmap et jalons](#roadmap-et-jalons)
7. [Risques et mitigations](#risques-et-mitigations)
8. [Livrables](#livrables)
9. [Stack technique](#stack-technique)

---

## Vision et contexte

### Objectif global
Exploiter des documents HTML pour :
1. **Classifier** automatiquement les pages produit vs non-produit (F1 â‰¥ 0.90)
2. **Extraire** des attributs clÃ©s avec normalisation rigoureuse (prix, devise, rÃ©fÃ©rence, dimensions, poids, etc.)
3. **Fournir** des explications et des scores de confiance pour chaque dÃ©cision

### Approche technique
- **Multi-source fusion** : Combiner JSON-LD, microdata, Open Graph, heuristiques textuelles avec rÃ©solution de conflits
- **Feature engineering riche** : Features structurelles, textuelles et sÃ©mantiques pour classification explicable
- **Normalisation stricte** : UnitÃ©s SI, ISO 4217, formats standardisÃ©s avec traÃ§abilitÃ©
- **Performance optimisÃ©e** : Target â‰¥50 pages/s avec I/O parallÃ¨le
- **PrioritÃ© FR** : Patterns et stopwords franÃ§ais, extensible multi-langues

### Analyse de l'existant âœ…

**Points forts :**
- âœ… Gestion d'erreurs avec type `Result<T>` uniforme
- âœ… Code modulaire (src/text/, src/stats/, src/math/)
- âœ… 75 tests unitaires (100% de rÃ©ussite)
- âœ… Documentation complÃ¨te dans `/documentations`
- âœ… Normalisation HTML avec 5 stratÃ©gies
- âœ… Analyse textuelle (TF, IDF, TF-IDF, co-occurrence, PCA)

**Ce qui manque :**
- âŒ Parser DOM structurÃ©
- âŒ Extraction mÃ©tadonnÃ©es e-commerce (Schema.org, Open Graph, JSON-LD)
- âŒ Classification automatique des pages
- âŒ Normalisation d'unitÃ©s (SI, ISO 4217)
- âŒ Pipeline unifiÃ© extraction + classification
- âŒ CLI d'analyse en lot

---

## KPI et mÃ©triques de succÃ¨s

### Classification (Produit vs Non-Produit)

| MÃ©trique | Sprint 2 (MVP) | Sprint 4 (OptimisÃ©) | Plan Final |
|----------|----------------|---------------------|------------|
| **F1-Score** | â‰¥ 0.87 | â‰¥ 0.92 | **â‰¥ 0.90** âœ“ |
| **PrÃ©cision** | â‰¥ 0.85 | â‰¥ 0.90 | **â‰¥ 0.88** âœ“ |
| **Rappel** | â‰¥ 0.90 | â‰¥ 0.95 | **â‰¥ 0.92** âœ“ |
| **Confiance moyenne** | â‰¥ 0.70 | â‰¥ 0.80 | **â‰¥ 0.75** âœ“ |
| **AUPRC** | - | - | **â‰¥ 0.92** âœ“ |

### Extraction de donnÃ©es

| Attribut | Objectif | Mesure |
|----------|----------|--------|
| **Prix + Devise** | **â‰¥ 98%** | Exactitude Â±0.01 unitÃ©, ISO 4217 |
| **RÃ©fÃ©rence/SKU** | **â‰¥ 95%** | Exact-match (case-insensitive) |
| **Nom produit** | **â‰¥ 90%** | PrÃ©sence + cohÃ©rence |
| **Marque** | **â‰¥ 85%** | Exact-match |
| **Poids** | **â‰¥ 90%** | Normalisation en grammes Â±1% |
| **Dimensions** | **â‰¥ 90%** | Normalisation en millimÃ¨tres Â±1% |
| **Images produit** | **â‰¥ 85%** | Comptage + pertinence |
| **JSON-LD Product** | **â‰¥ 95%** | DÃ©tection quand prÃ©sent |

### Performance

| MÃ©trique | Objectif |
|----------|----------|
| **Throughput** | **â‰¥ 50 pages/s** |
| **Latence par page** | < 20ms (en moyenne) |
| **Batch 100 pages** | < 5s (I/O parallÃ¨le) |
| **MÃ©moire** | < 500MB stable |
| **CPU** | â‰¤ 80% sur 4 cores |

---

## API publique

### Fonctions principales

```typescript
/**
 * Classifie une page HTML comme produit ou non-produit
 * @returns Score, label, features extraites, raisons explicatives
 */
export function isProductPage(
  html: string,
  opts?: ClassificationOptions
): Result<{
  score: number;           // 0-10
  label: boolean;          // true = produit
  confidence: number;      // 0-1
  features: PageFeatures;
  reasons: string[];       // Explications lisibles
}>;

/**
 * Extrait toutes les informations produit disponibles
 * @returns DonnÃ©es produit normalisÃ©es avec confiance et evidence
 */
export function extractProductInfo(
  html: string,
  opts?: ExtractionOptions
): Result<{
  product: ProductInfo;
  confidence: number;             // 0-1 global
  evidence: ExtractionEvidence[]; // TraÃ§abilitÃ© par source
}>;

/**
 * Analyse complÃ¨te : classification + extraction + analyse textuelle
 * Point d'entrÃ©e principal du pipeline
 */
export function analyzePage(
  html: string,
  opts?: AnalysisOptions
): Result<AnalysisResult>;

/**
 * Parse HTML et extrait mÃ©tadonnÃ©es structurÃ©es
 */
export function parseDom(
  html: string
): Result<{
  document: DomLike;
  jsonLd: any[];
  microdata: any[];
  openGraph: Record<string, string>;
  metadata: PageMetadata;
}>;

/**
 * Analyse batch avec parallÃ©lisation
 */
export async function analyzePages(
  htmlPages: Array<{ id: string; html: string }>,
  opts?: AnalysisOptions
): Promise<Result<Map<string, AnalysisResult>>>;

/**
 * Analyse d'un dossier complet
 */
export async function analyzeDirectory(
  dirpath: string,
  pattern?: string,
  opts?: AnalysisOptions
): Promise<Result<Map<string, AnalysisResult>>>;
```

### Types de donnÃ©es

```typescript
export interface ProductInfo {
  // Identifiants
  reference?: string;        // SKU, EAN, rÃ©fÃ©rence interne
  sku?: string;
  ean?: string;
  gtin13?: string;
  gtin14?: string;
  
  // Informations de base
  name?: string;
  brand?: string;
  model?: string;
  category?: string;
  description?: string;
  
  // Prix (normalisÃ©)
  price?: {
    amount: number;          // En centimes (EUR) ou cents (USD)
    currency: string;        // ISO 4217 (EUR, USD, GBP, etc.)
    originalValue: string;   // Valeur originale extraite
    confidence: number;      // 0-1
  };
  
  // CaractÃ©ristiques physiques (normalisÃ©es SI)
  weight?: {
    value: number;          // En grammes
    unit: 'g';              // Toujours g aprÃ¨s normalisation
    originalValue: string;
    originalUnit: string;
  };
  
  dimensions?: {
    length?: number;        // En millimÃ¨tres
    width?: number;
    height?: number;
    diameter?: number;
    unit: 'mm';            // Toujours mm aprÃ¨s normalisation
    originalValue: string;
  };
  
  // CapacitÃ©s Ã©lectriques (normalisÃ©es SI)
  battery?: {
    capacity: number;       // En mAh
    voltage?: number;       // En V
    power?: number;         // En W
  };
  
  // DisponibilitÃ©
  availability?: 'in_stock' | 'out_of_stock' | 'preorder' | 'discontinued' | 'unknown';
  stockQuantity?: number;
  
  // Images
  images?: Array<{
    url: string;
    alt?: string;
    width?: number;
    height?: number;
    isPrimary: boolean;
  }>;
  
  // MÃ©tadonnÃ©es
  condition?: 'new' | 'used' | 'refurbished' | 'unknown';
  warranty?: string;
  color?: string;
  size?: string;
  material?: string;
  
  // TraÃ§abilitÃ© extraction
  extractionMethods: Array<'jsonld' | 'microdata' | 'opengraph' | 'pattern' | 'context' | 'semantic'>;
  confidence: number;      // 0-1 confiance globale
}

export interface ExtractionEvidence {
  field: string;           // Nom du champ (ex: "price")
  value: any;              // Valeur extraite
  source: 'jsonld' | 'microdata' | 'opengraph' | 'pattern' | 'context' | 'semantic';
  confidence: number;      // 0-1
  location?: string;       // XPath ou sÃ©lecteur CSS
  rawText?: string;        // Texte original extrait
}

export interface PageFeatures {
  // Features structurelles HTML
  structural: {
    hasSchemaOrgProduct: boolean;
    hasOpenGraphProduct: boolean;
    hasJsonLdProduct: boolean;
    hasAddToCartButton: boolean;
    hasBuyButton: boolean;
    hasProductImages: boolean;
    hasRatings: boolean;
    hasPriceDisplay: boolean;
    imageCount: number;
    imageHighResCount: number;      // â‰¥ 300x300
    linkDensity: number;            // ratio liens/contenu
    tableCount: number;
    listCount: number;
    formCount: number;
  };
  
  // Features textuelles
  textual: {
    wordCount: number;
    digitDensity: number;           // ratio chiffres/mots
    ecommerceKeywordCount: number;  // "prix", "acheter", "panier", etc.
    productKeywordCount: number;    // "rÃ©fÃ©rence", "dimensions", etc.
    hasPrice: boolean;
    hasPriceLabel: boolean;         // "Prix", "Price", etc.
    hasReference: boolean;
    hasStock: boolean;
    hasShipping: boolean;
    hasWarranty: boolean;
    topTermsTfidf: Array<[string, number]>;
    language?: string;              // DÃ©tection langue
  };
  
  // Features sÃ©mantiques
  semantic: {
    hasSpecTable: boolean;          // Tableau de spÃ©cifications
    hasFeatureList: boolean;        // Liste de caractÃ©ristiques
    hasProductDescription: boolean;
    hasProductTitle: boolean;
    contentStructureScore: number;  // 0-10
    mainContentDensity: number;     // Ratio contenu principal/total
  };
  
  // Scores agrÃ©gÃ©s
  scores: {
    structuralScore: number;    // 0-10
    textualScore: number;       // 0-10
    semanticScore: number;      // 0-10
    overallScore: number;       // 0-10 (pondÃ©rÃ©)
  };
}

export interface AnalysisResult {
  // Classification
  classification: {
    isProductPage: boolean;
    confidence: number;
    score: number;           // 0-10
    reasons: string[];       // Explications lisibles
    features: PageFeatures;
  };
  
  // DonnÃ©es produit (si page produit)
  productData?: ProductInfo;
  evidence?: ExtractionEvidence[];
  
  // Analyse textuelle
  textAnalysis: {
    wordCount: number;
    topTerms: Array<[string, number]>;
    keyPhrases: string[];
    language?: string;
  };
  
  // MÃ©tadonnÃ©es page
  metadata: {
    title?: string;
    description?: string;
    keywords?: string[];
    language?: string;
    canonical?: string;
  };
  
  // Statistiques traitement
  processingTime: number;
  stepsCompleted: string[];
  errors?: string[];
}
```

---

## Architecture technique

### Vue d'ensemble du pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HTML INPUT                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: PARSING DOM & NORMALISATION                       â”‚
â”‚  - Parse HTML (linkedom)                                     â”‚
â”‚  - Extraction JSON-LD, microdata, Open Graph                 â”‚
â”‚  - Normalisation HTML (WITH_METADATA)                        â”‚
â”‚  - DÃ©tection contenu principal (densitÃ©, nav removal)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: FEATURE ENGINEERING                                â”‚
â”‚  - Features structurelles (JSON-LD, boutons, forms)         â”‚
â”‚  - Features textuelles (TF-IDF, keywords, digit density)    â”‚
â”‚  - Features sÃ©mantiques (tables, lists, content structure)  â”‚
â”‚  - Calcul scores pondÃ©rÃ©s                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: CLASSIFICATION                                     â”‚
â”‚  - Scoring multi-critÃ¨res (structural Ã— 0.5 + textual Ã— 0.3 â”‚
â”‚    + semantic Ã— 0.2)                                         â”‚
â”‚  - DÃ©cision: seuil calibrÃ© (dÃ©faut 5.0/10)                 â”‚
â”‚  - GÃ©nÃ©ration raisons explicatives                          â”‚
â”‚  - Calcul confiance basÃ© sur distance au seuil             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º NON-PRODUIT â†’ RÃ©sultat minimal
                       â”‚
                       â–¼ PRODUIT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: EXTRACTION MULTI-SOURCE                            â”‚
â”‚  - PrioritÃ©: JSON-LD > microdata > OpenGraph > patterns     â”‚
â”‚  - Normalisation unitÃ©s (SI, ISO 4217)                      â”‚
â”‚  - Fusion avec rÃ©solution conflits                          â”‚
â”‚  - Evidence tracking dÃ©taillÃ©                               â”‚
â”‚  - Context-aware extraction (proximitÃ© textuelle)           â”‚
â”‚  - Semantic extraction (tableaux specs, listes)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 5: ANALYSE TEXTUELLE (Optionnelle)                   â”‚
â”‚  - TF-IDF top termes                                        â”‚
â”‚  - Extraction key phrases                                   â”‚
â”‚  - Co-occurrence analysis                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RÃ‰SULTAT ENRICHI                                            â”‚
â”‚  - Classification + confiance + explications                 â”‚
â”‚  - DonnÃ©es produit normalisÃ©es + evidence                    â”‚
â”‚  - Analyse textuelle (top termes, keyphrases)               â”‚
â”‚  - MÃ©tadonnÃ©es + statistiques traitement                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Organisation des modules

```
src/
â”œâ”€â”€ html/                        # NOUVEAU - Parsing HTML
â”‚   â”œâ”€â”€ parser.ts               # Parser DOM (linkedom wrapper)
â”‚   â”œâ”€â”€ content_extractor.ts    # Extraction contenu principal
â”‚   â”œâ”€â”€ dom_utils.ts            # Utilitaires DOM (querySelector, etc.)
â”‚   â”œâ”€â”€ parser_types.ts         # Types (DOMNode, ParseOptions)
â”‚   â””â”€â”€ parser_test.ts
â”‚
â”œâ”€â”€ extraction/                  # NOUVEAU - Extraction donnÃ©es produit
â”‚   â”œâ”€â”€ product_extractor.ts   # Orchestration extraction principale
â”‚   â”œâ”€â”€ schema_parser.ts        # Schema.org, Open Graph, JSON-LD
â”‚   â”œâ”€â”€ pattern_matcher.ts      # Patterns regex (prix, ref, dimensions)
â”‚   â”œâ”€â”€ semantic_extractor.ts   # Extraction tableaux, listes specs
â”‚   â”œâ”€â”€ context_extractor.ts    # Extraction par proximitÃ© textuelle
â”‚   â”œâ”€â”€ normalizer.ts           # Normalisation unitÃ©s (SI, ISO 4217)
â”‚   â”œâ”€â”€ fusion.ts               # Fusion multi-source + rÃ©solution conflits
â”‚   â”œâ”€â”€ patterns.ts             # BibliothÃ¨que patterns FR/EN
â”‚   â”œâ”€â”€ extraction_types.ts     # Types (ProductInfo, Evidence, etc.)
â”‚   â””â”€â”€ extraction_test.ts
â”‚
â”œâ”€â”€ classification/              # NOUVEAU - Classification pages
â”‚   â”œâ”€â”€ features.ts             # Feature engineering
â”‚   â”œâ”€â”€ rule_classifier.ts      # Classificateur basÃ© sur rÃ¨gles
â”‚   â”œâ”€â”€ scoring.ts              # SystÃ¨me de scoring dÃ©taillÃ©
â”‚   â”œâ”€â”€ ml_classifier.ts        # Classificateur ML (Sprint 4, optionnel)
â”‚   â”œâ”€â”€ calibration.ts          # Calibration seuils (AUPRC, F1)
â”‚   â”œâ”€â”€ classification_types.ts # Types (Features, ClassificationResult)
â”‚   â””â”€â”€ classification_test.ts
â”‚
â”œâ”€â”€ pipeline/                    # NOUVEAU - Pipeline unifiÃ©
â”‚   â”œâ”€â”€ analyzer.ts             # Pipeline principal
â”‚   â”œâ”€â”€ batch_processor.ts      # Traitement parallÃ¨le batch
â”‚   â”œâ”€â”€ formatters.ts           # Export JSON, CSV, Markdown, texte
â”‚   â”œâ”€â”€ reporters.ts            # GÃ©nÃ©ration rapports mÃ©triques
â”‚   â”œâ”€â”€ analyzer_types.ts       # Types (AnalysisOptions, AnalysisResult)
â”‚   â””â”€â”€ analyzer_test.ts
â”‚
â”œâ”€â”€ cli/                         # NOUVEAU - Interface CLI
â”‚   â”œâ”€â”€ analyze.ts              # Commande principale
â”‚   â”œâ”€â”€ commands.ts             # Sous-commandes (extract, classify, etc.)
â”‚   â”œâ”€â”€ config.ts               # Configuration CLI
â”‚   â””â”€â”€ output.ts               # Formatage sortie console
â”‚
â”œâ”€â”€ text/                        # EXISTANT - Modules texte (AMÃ‰LIORÃ‰)
â”‚   â”œâ”€â”€ normalize.ts            # âœ… DÃ©jÃ  implÃ©mentÃ©
â”‚   â”œâ”€â”€ tokenize.ts             # âœ… AmÃ©liorÃ© (digits, n-grams, stopwords FR)
â”‚   â”œâ”€â”€ tf.ts, idf.ts, tfidf.ts # âœ… DÃ©jÃ  implÃ©mentÃ©
â”‚   â”œâ”€â”€ cooccurrence.ts         # âœ… DÃ©jÃ  implÃ©mentÃ©
â”‚   â””â”€â”€ stopwords_fr.ts         # NOUVEAU - Liste stopwords franÃ§ais
â”‚
â”œâ”€â”€ stats/                       # EXISTANT - Statistiques
â”‚   â””â”€â”€ ...                     # âœ… DÃ©jÃ  implÃ©mentÃ©
â”‚
â”œâ”€â”€ math/                        # EXISTANT - Matrices, algÃ¨bre
â”‚   â””â”€â”€ ...                     # âœ… DÃ©jÃ  implÃ©mentÃ©
â”‚
â””â”€â”€ types/
    â””â”€â”€ result.ts               # âœ… DÃ©jÃ  implÃ©mentÃ©
```

---

## SpÃ©cifications fonctionnelles

### 1. Parsing DOM et contenu principal

#### 1.1 Parser HTML structurÃ© (`src/html/parser.ts`)

**Objectif :** Wrapper robuste autour de linkedom pour Deno

**FonctionnalitÃ©s :**
- Parse HTML en structure DOM navigable
- Support sÃ©lecteurs CSS complets
- Extraction JSON-LD, microdata, Open Graph
- Gestion entitÃ©s HTML et encodage
- TolÃ©rance aux erreurs (HTML malformÃ©)

**API :**
```typescript
export function parseHtml(html: string, opts?: ParseOptions): Result<ParsedDocument>;
export function querySelector(root: DOMNode, selector: string): Result<DOMNode | null>;
export function querySelectorAll(root: DOMNode, selector: string): Result<DOMNode[]>;
export function extractJsonLd(document: DOMNode): Result<any[]>;
export function extractMicrodata(document: DOMNode): Result<any[]>;
export function extractOpenGraph(document: DOMNode): Result<Record<string, string>>;
```

#### 1.2 Extraction contenu principal (`src/html/content_extractor.ts`)

**Objectif :** Isoler le contenu principal pour amÃ©liorer features textuelles

**Heuristiques :**
- Calcul densitÃ© texte/liens par bloc
- Suppression navigation, header, footer, sidebar
- DÃ©tection sections rÃ©pÃ©titives (menus, ads)
- Score de pertinence par nÅ“ud DOM

**API :**
```typescript
export function extractMainContent(document: DOMNode): Result<{
  mainContent: string;
  mainContentNode: DOMNode;
  contentDensity: number;
  removedNodes: string[]; // Types de nÅ“uds supprimÃ©s
}>;
```

### 2. Feature Engineering

#### 2.1 Features structurelles (`src/classification/features.ts`)

**Extraction automatique depuis DOM :**
```typescript
structural: {
  hasSchemaOrgProduct: boolean;          // itemtype="Product"
  hasOpenGraphProduct: boolean;          // og:type="product"
  hasJsonLdProduct: boolean;             // @type="Product"
  hasAddToCartButton: boolean;           // Bouton "Ajouter au panier"
  hasBuyButton: boolean;                 // Bouton "Acheter"
  hasProductImages: boolean;             // Images â‰¥ 300x300
  hasRatings: boolean;                   // Ã‰toiles, avis
  hasPriceDisplay: boolean;              // Affichage prix stylisÃ©
  imageCount: number;
  imageHighResCount: number;
  linkDensity: number;                   // < 0.3 typique pour produits
  tableCount: number;
  listCount: number;
  formCount: number;
}
```

**Scoring :** `structuralScore = Î£(feature Ã— weight) / maxScore Ã— 10`

#### 2.2 Features textuelles (`src/classification/features.ts`)

**Extraction depuis texte normalisÃ© :**
```typescript
textual: {
  wordCount: number;
  digitDensity: number;                  // Produits ont souvent beaucoup de chiffres
  ecommerceKeywordCount: number;         // "prix", "acheter", "livraison", etc.
  productKeywordCount: number;           // "rÃ©fÃ©rence", "dimensions", "poids"
  hasPrice: boolean;
  hasPriceLabel: boolean;
  hasReference: boolean;
  hasStock: boolean;
  hasShipping: boolean;
  hasWarranty: boolean;
  topTermsTfidf: Array<[string, number]>;
  language?: string;
}
```

**Mots-clÃ©s e-commerce FR/EN :**
```typescript
export const ECOMMERCE_KEYWORDS = [
  // FR
  'prix', 'acheter', 'ajouter', 'panier', 'commander', 'livraison',
  'stock', 'disponible', 'garantie', 'retour', 'remboursement',
  // EN
  'price', 'buy', 'add', 'cart', 'order', 'shipping', 'delivery',
  'stock', 'available', 'warranty', 'return', 'refund'
];
```

**Scoring :** `textualScore = f(keywordDensity, digitDensity, price presence, ...)`

#### 2.3 Features sÃ©mantiques (`src/classification/features.ts`)

**Analyse structure contenu :**
```typescript
semantic: {
  hasSpecTable: boolean;                 // <table> avec "CaractÃ©ristiques"
  hasFeatureList: boolean;               // <ul>/<dl> avec specs
  hasProductDescription: boolean;        // Bloc description dÃ©taillÃ©e
  hasProductTitle: boolean;              // <h1> type produit
  contentStructureScore: number;         // 0-10 qualitÃ© structure
  mainContentDensity: number;            // Ratio contenu principal/total
}
```

### 3. Classification

#### 3.1 Classificateur basÃ© sur rÃ¨gles (`src/classification/rule_classifier.ts`)

**Formule de scoring :**
```typescript
overallScore = 
  (structuralScore Ã— 0.5) +
  (textualScore Ã— 0.3) +
  (semanticScore Ã— 0.2)

isProductPage = overallScore >= threshold (dÃ©faut: 5.0)

confidence = sigmoid((overallScore - threshold) / 2.0)
```

**GÃ©nÃ©ration raisons explicatives :**
```typescript
reasons = [
  "âœ“ JSON-LD Product dÃ©tectÃ©",
  "âœ“ Prix trouvÃ©: 120.00 EUR",
  "âœ“ RÃ©fÃ©rence produit: 23572714",
  "âœ“ Tableau de spÃ©cifications prÃ©sent",
  "âš  Pas de bouton 'Ajouter au panier'",
  "âš  Faible densitÃ© d'images"
]
```

#### 3.2 Calibration des seuils (`src/classification/calibration.ts`)

**MÃ©thode :**
1. Annoter dataset de validation (produit/non-produit)
2. Calculer scores sur tout le dataset
3. GÃ©nÃ©rer courbe Precision-Recall
4. SÃ©lectionner seuil maximisant F1 ou AUPRC
5. Valider sur test set sÃ©parÃ©

**API :**
```typescript
export function calibrateThreshold(
  examples: LabeledExample[],
  metric: 'f1' | 'auprc'
): Result<{
  optimalThreshold: number;
  f1Score: number;
  precision: number;
  recall: number;
  auprc: number;
}>;
```

### 4. Extraction multi-source

#### 4.1 Extraction JSON-LD / Microdata / Open Graph (`src/extraction/schema_parser.ts`)

**PrioritÃ© :** JSON-LD > Microdata > Open Graph

**Standards supportÃ©s :**

**JSON-LD (prioritÃ© 1) :**
```json
{
  "@context": "https://schema.org/",
  "@type": "Product",
  "name": "Compresseur air conditionnÃ© PEUGEOT 307",
  "sku": "23572714",
  "brand": { "@type": "Brand", "name": "PEUGEOT" },
  "offers": {
    "@type": "Offer",
    "price": "120.00",
    "priceCurrency": "EUR",
    "availability": "https://schema.org/InStock"
  },
  "weight": { "@type": "QuantitativeValue", "value": "2.5", "unitCode": "KGM" },
  "image": "https://example.com/product.jpg"
}
```

**Microdata (prioritÃ© 2) :**
```html
<div itemscope itemtype="https://schema.org/Product">
  <span itemprop="name">Compresseur</span>
  <span itemprop="price">120.00</span>
  <span itemprop="priceCurrency">EUR</span>
</div>
```

**Open Graph (prioritÃ© 3) :**
```html
<meta property="og:type" content="product">
<meta property="product:price:amount" content="120.00">
<meta property="product:price:currency" content="EUR">
```

#### 4.2 Extraction par patterns regex (`src/extraction/pattern_matcher.ts`)

**BibliothÃ¨que patterns FR/EN :**
```typescript
export const PATTERNS = {
  // Prix (multi-formats)
  PRICE_EUR_SYMBOL: /(\d+(?:[.,]\d{2})?)\s*â‚¬/g,
  PRICE_EUR_CODE: /(\d+(?:[.,]\d{2})?)\s*EUR/gi,
  PRICE_LABELED_FR: /prix[\s:]*(\d+[.,]\d{2})/gi,
  PRICE_LABELED_EN: /price[\s:]*(\d+[.,]\d{2})/gi,
  PRICE_USD: /\$\s*(\d+(?:[.,]\d{2})?)/g,
  
  // RÃ©fÃ©rence/SKU (multi-formats)
  REF_LABELED_FR: /rÃ©f(?:Ã©rence)?[\s:.]*([A-Z0-9-]{4,20})/gi,
  REF_LABELED_EN: /ref(?:erence)?[\s:.]*([A-Z0-9-]{4,20})/gi,
  SKU_LABELED: /SKU[\s:.]*([A-Z0-9-]{4,20})/gi,
  EAN: /EAN[\s:.]*(\d{13})/gi,
  GTIN: /GTIN[\s:.]*(\d{8,14})/gi,
  
  // Poids (normalisation vers grammes)
  WEIGHT_KG: /(\d+(?:[.,]\d+)?)\s*kg/gi,
  WEIGHT_G: /(\d+)\s*g(?:rammes?)?/gi,
  WEIGHT_LABELED_FR: /poids[\s:]*(\d+(?:[.,]\d+)?)\s*(kg|g)/gi,
  WEIGHT_LABELED_EN: /weight[\s:]*(\d+(?:[.,]\d+)?)\s*(kg|g)/gi,
  
  // Dimensions (normalisation vers mm)
  DIMENSIONS_3D: /(\d+)\s*[xÃ—]\s*(\d+)\s*[xÃ—]\s*(\d+)\s*(mm|cm|m)/gi,
  DIMENSIONS_2D: /(\d+)\s*[xÃ—]\s*(\d+)\s*(mm|cm|m)/gi,
  LENGTH_LABELED: /longueur[\s:]*(\d+)\s*(mm|cm|m)/gi,
  WIDTH_LABELED: /largeur[\s:]*(\d+)\s*(mm|cm|m)/gi,
  HEIGHT_LABELED: /hauteur[\s:]*(\d+)\s*(mm|cm|m)/gi,
  
  // Stock/DisponibilitÃ©
  IN_STOCK_FR: /en\s+stock|disponible/gi,
  OUT_OF_STOCK_FR: /rupture|indisponible|Ã©puisÃ©/gi,
  IN_STOCK_EN: /in\s+stock|available/gi,
  OUT_OF_STOCK_EN: /out\s+of\s+stock|unavailable|sold\s+out/gi,
};
```

#### 4.3 Normalisation d'unitÃ©s (`src/extraction/normalizer.ts`)

**Objectif :** UnitÃ©s SI + ISO 4217 pour comparabilitÃ©

**RÃ¨gles de normalisation :**

```typescript
// Prix â†’ centimes + ISO 4217
"120.00 â‚¬" â†’ { amount: 12000, currency: "EUR" }
"$99.99"   â†’ { amount: 9999, currency: "USD" }
"45,50 EUR" â†’ { amount: 4550, currency: "EUR" }

// Poids â†’ grammes
"2.5 kg"   â†’ { value: 2500, unit: "g" }
"500 g"    â†’ { value: 500, unit: "g" }
"1.2kg"    â†’ { value: 1200, unit: "g" }

// Dimensions â†’ millimÃ¨tres
"30 x 20 x 10 cm" â†’ { length: 300, width: 200, height: 100, unit: "mm" }
"1.5 m"           â†’ { value: 1500, unit: "mm" }
"250 mm"          â†’ { value: 250, unit: "mm" }

// CapacitÃ© batterie â†’ mAh
"3000 mAh" â†’ { capacity: 3000, unit: "mAh" }
"3 Ah"     â†’ { capacity: 3000, unit: "mAh" }
```

**API :**
```typescript
export function normalizePrice(value: string, currency?: string): Result<Money>;
export function normalizeWeight(value: string | number, unit: string): Result<Weight>;
export function normalizeDimension(value: string | number, unit: string): Result<number>; // mm
export function normalizeBatteryCapacity(value: string | number, unit: string): Result<number>; // mAh
```

#### 4.4 Extraction context-aware (`src/extraction/context_extractor.ts`)

**Objectif :** Trouver valeurs par proximitÃ© textuelle avec mots-clÃ©s

**MÃ©thode :**
1. Tokenizer le texte avec positions
2. Trouver occurrences de mots-clÃ©s ("Prix", "RÃ©fÃ©rence", etc.)
3. Chercher patterns dans fenÃªtre de N tokens autour
4. Scorer par distance au mot-clÃ©

**Exemple :**
```
Texte: "... RÃ©fÃ©rence fabricant : 23572714. Ce compresseur ..."
       â†‘ keyword         â†‘ value (distance: 2 tokens)
```

**API :**
```typescript
export function extractByContext(
  text: string,
  keywords: string[],
  pattern: RegExp,
  windowSize?: number  // dÃ©faut: 10 tokens
): Result<Array<{
  value: string;
  keyword: string;
  distance: number;
  confidence: number;
}>>;
```

#### 4.5 Extraction sÃ©mantique (`src/extraction/semantic_extractor.ts`)

**Objectif :** Extraire depuis tableaux HTML et listes structurÃ©es

**Tableaux de spÃ©cifications :**
```html
<table>
  <tr><td>RÃ©fÃ©rence</td><td>23572714</td></tr>
  <tr><td>Poids</td><td>2.5 kg</td></tr>
  <tr><td>Dimensions</td><td>30 x 20 x 10 cm</td></tr>
</table>
```

**Listes de caractÃ©ristiques :**
```html
<dl>
  <dt>SKU</dt><dd>ABC123</dd>
  <dt>Marque</dt><dd>PEUGEOT</dd>
</dl>
```

**API :**
```typescript
export function extractFromTable(
  tableNode: DOMNode,
  keyColumn?: number,
  valueColumn?: number
): Result<Record<string, string>>;

export function extractFromList(
  listNode: DOMNode,
  listType: 'dl' | 'ul'
): Result<Record<string, string>>;
```

#### 4.6 Fusion multi-source (`src/extraction/fusion.ts`)

**Objectif :** RÃ©soudre conflits entre sources et maximiser confiance

**StratÃ©gie de fusion :**
1. **PondÃ©ration par source :**
   - JSON-LD : poids 1.0
   - Microdata : poids 0.8
   - Open Graph : poids 0.6
   - Pattern + context : poids 0.4
   - Pattern seul : poids 0.3

2. **RÃ©solution conflits :**
   - Si valeurs identiques â†’ confiance maximale
   - Si valeurs proches (Â±1%) â†’ moyenne pondÃ©rÃ©e
   - Si valeurs divergentes â†’ prendre source prioritaire

3. **Evidence tracking :**
   - Enregistrer toutes les sources pour chaque champ
   - Fournir traÃ§abilitÃ© complÃ¨te

**API :**
```typescript
export function mergeProductData(
  sources: Array<{
    data: Partial<ProductInfo>;
    source: ExtractionMethod;
    weight: number;
  }>
): Result<{
  merged: ProductInfo;
  evidence: ExtractionEvidence[];
  conflicts: Array<{
    field: string;
    values: any[];
    resolution: string;
  }>;
}>;
```

### 5. Pipeline unifiÃ©

#### 5.1 Orchestration principale (`src/pipeline/analyzer.ts`)

**ImplÃ©mentation du pipeline :**

```typescript
export function analyzePage(
  html: string,
  opts: AnalysisOptions = {}
): Result<AnalysisResult> {
  const startTime = performance.now();
  const stepsCompleted: string[] = [];
  const errors: string[] = [];
  
  // Ã‰TAPE 1: Parsing DOM
  const [parseErr, parsed] = parseDom(html);
  if (parseErr) return fail(parseErr);
  stepsCompleted.push('parsing');
  
  // Ã‰TAPE 2: Normalisation HTML
  const [normErr, normalized] = normalizeHtml(html, {
    strategy: opts.normalizationStrategy ?? 'WITH_METADATA'
  });
  if (normErr) return fail(normErr);
  stepsCompleted.push('normalization');
  
  // Ã‰TAPE 3: Extraction contenu principal
  const [contentErr, mainContent] = extractMainContent(parsed.document);
  if (contentErr) errors.push(`Content extraction: ${contentErr.message}`);
  stepsCompleted.push('content_extraction');
  
  // Ã‰TAPE 4: Feature engineering
  const [featErr, features] = extractFeatures(html, normalized, mainContent);
  if (featErr) return fail(featErr);
  stepsCompleted.push('features');
  
  // Ã‰TAPE 5: Classification
  let classification: ClassificationResult;
  if (!opts.skipClassification) {
    const [classErr, classResult] = classifyPage(features, opts.classifierRules);
    if (classErr) return fail(classErr);
    classification = classResult;
    stepsCompleted.push('classification');
  }
  
  // Ã‰TAPE 6: Extraction produit (si page produit)
  let productData: ProductInfo | undefined;
  let evidence: ExtractionEvidence[] | undefined;
  
  if (opts.skipClassification || classification.isProductPage) {
    const [extractErr, extracted] = extractProductInfo(html, parsed, opts.extractionOptions);
    if (extractErr) {
      errors.push(`Extraction: ${extractErr.message}`);
    } else {
      productData = extracted.product;
      evidence = extracted.evidence;
      stepsCompleted.push('extraction');
    }
  }
  
  // Ã‰TAPE 7: Analyse textuelle TF-IDF (optionnelle)
  let topTerms: Array<[string, number]> = [];
  if (opts.computeTfidf ?? true) {
    const [tfErr, tf] = termFrequency(normalized.text, { asRelative: true });
    if (!tfErr) {
      topTerms = Object.entries(tf)
        .sort((a, b) => b[1] - a[1])
        .slice(0, opts.topTermsCount ?? 20);
      stepsCompleted.push('tfidf');
    }
  }
  
  // Ã‰TAPE 8: Assemblage rÃ©sultat
  const result: AnalysisResult = {
    classification: {
      isProductPage: classification?.isProductPage ?? false,
      confidence: classification?.confidence ?? 0,
      score: classification?.score ?? 0,
      reasons: classification?.reasons ?? [],
      features
    },
    productData,
    evidence,
    textAnalysis: {
      wordCount: normalized.text.split(/\s+/).length,
      topTerms,
      keyPhrases: [],
      language: normalized.metadata?.language
    },
    metadata: normalized.metadata ?? {},
    processingTime: performance.now() - startTime,
    stepsCompleted,
    errors: errors.length > 0 ? errors : undefined
  };
  
  return ok(result);
}
```

#### 5.2 Traitement batch parallÃ¨le (`src/pipeline/batch_processor.ts`)

**Objectif :** Analyser 100+ pages en parallÃ¨le avec contrÃ´le concurrence

**API :**
```typescript
export async function analyzePagesBatch(
  pages: Array<{ id: string; html: string }>,
  opts?: AnalysisOptions & { concurrency?: number }
): Promise<Result<Map<string, AnalysisResult>>> {
  const concurrency = opts?.concurrency ?? 10;
  const results = new Map<string, AnalysisResult>();
  
  // Traitement par chunks parallÃ¨les
  for (let i = 0; i < pages.length; i += concurrency) {
    const chunk = pages.slice(i, i + concurrency);
    const promises = chunk.map(async ({ id, html }) => {
      const [err, result] = analyzePage(html, opts);
      if (!err) results.set(id, result);
      return { id, err, result };
    });
    
    await Promise.all(promises);
  }
  
  return ok(results);
}
```

#### 5.3 Formatters (`src/pipeline/formatters.ts`)

**Formats de sortie supportÃ©s :**

```typescript
// JSON (dÃ©taillÃ© ou compact)
export function formatAsJson(result: AnalysisResult, pretty?: boolean): string;

// CSV (pour batch analysis)
export function formatAsCsv(results: Map<string, AnalysisResult>): string;

// Markdown (rapport lisible)
export function formatAsMarkdown(result: AnalysisResult): string;

// Texte (console-friendly)
export function formatAsText(result: AnalysisResult): string;

// Rapport comparatif
export function generateComparisonReport(
  results: Map<string, AnalysisResult>
): string;
```

**Exemple sortie Markdown :**
```markdown
# Analyse: pieceoccasion-1.html

## Classification
- **Type:** Page Produit âœ“
- **Confiance:** 0.89
- **Score:** 7.8/10

### Raisons
âœ“ JSON-LD Product dÃ©tectÃ©
âœ“ Prix trouvÃ©: 120.00 EUR
âœ“ RÃ©fÃ©rence produit: 23572714
âœ“ Tableau de spÃ©cifications prÃ©sent
âš  Pas de bouton 'Ajouter au panier'

## DonnÃ©es Produit
- **Nom:** Compresseur air conditionnÃ© PEUGEOT 307
- **Prix:** 120.00 EUR (confiance: 0.95)
- **RÃ©fÃ©rence:** 23572714
- **Marque:** PEUGEOT
- **DisponibilitÃ©:** En stock

## Statistiques
- Temps de traitement: 12.5ms
- Ã‰tapes complÃ©tÃ©es: 7/7
```

### 6. CLI

#### 6.1 Interface ligne de commande (`cli/analyze.ts`)

**Commandes principales :**

```bash
# Analyser un fichier
deno run -A cli/analyze.ts --file dataset/pieceoccasion-1.html --format json

# Analyser un dossier
deno run -A cli/analyze.ts --dir dataset/ --pattern "*.html" --format csv --out results.csv

# Classification seulement (plus rapide)
deno run -A cli/analyze.ts --dir dataset/ --classify-only --format json

# Extraction seulement (pour pages dÃ©jÃ  identifiÃ©es comme produits)
deno run -A cli/analyze.ts --dir dataset/ --extract-only --format json

# Avec options avancÃ©es
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --format json \
  --out results.json \
  --concurrency 20 \
  --threshold 5.5 \
  --tfidf \
  --top-terms 30

# GÃ©nÃ©ration rapport mÃ©triques (avec ground truth)
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --ground-truth labels.json \
  --metrics-report
```

**Options disponibles :**
```typescript
interface CliOptions {
  // Input
  file?: string;
  dir?: string;
  pattern?: string;
  
  // Output
  out?: string;
  format: 'json' | 'csv' | 'markdown' | 'text';
  pretty?: boolean;
  
  // Processing
  concurrency?: number;
  classifyOnly?: boolean;
  extractOnly?: boolean;
  skipClassification?: boolean;
  
  // Classification
  threshold?: number;
  structuralWeight?: number;
  textualWeight?: number;
  semanticWeight?: number;
  
  // Extraction
  enableJsonLd?: boolean;
  enableMicrodata?: boolean;
  enableOpenGraph?: boolean;
  enablePatterns?: boolean;
  
  // Text analysis
  tfidf?: boolean;
  topTerms?: number;
  
  // Evaluation
  groundTruth?: string;
  metricsReport?: boolean;
  
  // Debug
  verbose?: boolean;
  includeFeatures?: boolean;
  includeEvidence?: boolean;
}
```

---

## Roadmap et jalons

### Sprint 0 : PrÃ©paration (1 jour)

**Objectifs :**
- âœ… Validation plan final
- âœ… Setup dÃ©pendances (linkedom)
- âœ… CrÃ©ation structure de dossiers
- âœ… Types de base

**Livrables :**
- `src/html/parser_types.ts`
- `src/extraction/extraction_types.ts`
- `src/classification/classification_types.ts`
- `src/pipeline/analyzer_types.ts`
- `deno.json` avec dÃ©pendances

**CritÃ¨res de succÃ¨s :**
- [ ] Projet compile sans erreurs
- [ ] linkedom importable
- [ ] Types validÃ©s

---

### Sprint 1 : Parsing & Extraction de base (3 jours)

**Objectifs :**
- âœ… Parser DOM + linkedom wrapper
- âœ… Extraction JSON-LD, microdata, Open Graph
- âœ… Patterns regex (prix, rÃ©fÃ©rence)
- âœ… Normalisation unitÃ©s (SI, ISO 4217)
- âœ… Tests sur dataset

**Livrables :**
- `src/html/parser.ts`
- `src/html/dom_utils.ts`
- `src/extraction/schema_parser.ts`
- `src/extraction/pattern_matcher.ts`
- `src/extraction/normalizer.ts`
- `src/extraction/patterns.ts`
- Tests unitaires (â‰¥20 tests)

**CritÃ¨res de succÃ¨s :**
- [ ] Prix extrait et normalisÃ© sur 3/3 pages produit (Â±0.01)
- [ ] RÃ©fÃ©rence extraite sur 3/3 pages produit (exact-match)
- [ ] JSON-LD dÃ©tectÃ© correctement (100%)
- [ ] Normalisation EUR/USD/GBP fonctionnelle
- [ ] Normalisation kg/g/mm/cm fonctionnelle
- [ ] 0 erreur sur pages non-produit

---

### Sprint 2 : Classification complÃ¨te (3 jours)

**Objectifs :**
- âœ… Feature engineering (structural, textual, semantic)
- âœ… Content extractor (densitÃ©, nav removal)
- âœ… Classificateur basÃ© sur rÃ¨gles
- âœ… SystÃ¨me de scoring dÃ©taillÃ©
- âœ… GÃ©nÃ©ration raisons explicatives
- âœ… Tests de classification

**Livrables :**
- `src/html/content_extractor.ts`
- `src/classification/features.ts`
- `src/classification/rule_classifier.ts`
- `src/classification/scoring.ts`
- `src/text/stopwords_fr.ts`
- Tests unitaires (â‰¥25 tests)

**CritÃ¨res de succÃ¨s :**
- [ ] F1 â‰¥ 0.90 sur dataset (6 fichiers)
- [ ] PrÃ©cision â‰¥ 0.88
- [ ] Rappel â‰¥ 0.92
- [ ] Confiance moyenne â‰¥ 0.75
- [ ] Aucun faux nÃ©gatif sur pages produit (rappel 100%)
- [ ] Raisons explicatives gÃ©nÃ©rÃ©es pour toutes les pages

---

### Sprint 3 : Pipeline & CLI (2 jours)

**Objectifs :**
- âœ… Pipeline unifiÃ©
- âœ… Extraction multi-source complÃ¨te (context, semantic)
- âœ… Fusion avec rÃ©solution conflits
- âœ… Batch processor parallÃ¨le
- âœ… Formatters (JSON, CSV, Markdown, texte)
- âœ… CLI complet
- âœ… Documentation utilisateur

**Livrables :**
- `src/extraction/context_extractor.ts`
- `src/extraction/semantic_extractor.ts`
- `src/extraction/fusion.ts`
- `src/extraction/product_extractor.ts` (orchestration)
- `src/pipeline/analyzer.ts`
- `src/pipeline/batch_processor.ts`
- `src/pipeline/formatters.ts`
- `cli/analyze.ts`
- `cli/commands.ts`
- `documentations/USER_GUIDE.md`
- Tests d'intÃ©gration (â‰¥10 tests)

**CritÃ¨res de succÃ¨s :**
- [ ] Pipeline fonctionne sur tout le dataset (6/6)
- [ ] Batch 100 pages < 5s (target: 50+ pages/s)
- [ ] CLI produit JSON/CSV/Markdown valides
- [ ] Evidence tracking complet pour toutes extractions
- [ ] Fusion rÃ©sout correctement les conflits
- [ ] Documentation utilisateur complÃ¨te

---

### Sprint 4 : AmÃ©lioration & Production (3-5 jours, optionnel)

**Objectifs :**
- âœ… Extraction avancÃ©e (dimensions 3D, capacitÃ©s Ã©lectriques)
- âœ… Calibration seuils (AUPRC, F1)
- âœ… Classificateur ML (rÃ©gression logistique)
- âœ… Benchmarks et mÃ©triques dÃ©taillÃ©es
- âœ… Optimisation performance
- âœ… Extension multi-langues (EN, ES)
- âœ… Documentation complÃ¨te

**Livrables :**
- `src/classification/ml_classifier.ts`
- `src/classification/calibration.ts`
- `tests/benchmarks/classification_metrics.ts`
- `tests/benchmarks/extraction_precision.ts`
- `tools/dataset_annotator.ts`
- `tools/metrics_reporter.ts`
- `documentations/CLASSIFICATION_GUIDE.md`
- `documentations/EXTRACTION_GUIDE.md`
- `documentations/PATTERNS_REFERENCE.md`

**CritÃ¨res de succÃ¨s :**
- [ ] F1 â‰¥ 0.95 avec ML
- [ ] AUPRC â‰¥ 0.92
- [ ] Extraction dimensions 3D â‰¥ 90%
- [ ] Extraction poids â‰¥ 90%
- [ ] Throughput â‰¥ 50 pages/s
- [ ] MÃ©moire < 500MB stable
- [ ] Documentation technique complÃ¨te

---

## Risques et mitigations

### Risque 1 : HTML hÃ©tÃ©rogÃ¨ne / anti-scraping

**Impact :** Ã‰chec parsing ou extraction incomplÃ¨te  
**ProbabilitÃ© :** Haute  
**Mitigations :**
- âœ… PrivilÃ©gier JSON-LD (standard structurÃ©)
- âœ… TolÃ©rance aux erreurs DOM (try/catch)
- âœ… Fallback sur patterns regex si DOM Ã©choue
- âœ… Content extractor pour isoler contenu principal
- âœ… Tests sur HTML rÃ©els variÃ©s

### Risque 2 : Formats prix/unitÃ©s variÃ©s

**Impact :** Extraction incorrecte ou normalisation Ã©chouÃ©e  
**ProbabilitÃ© :** Moyenne  
**Mitigations :**
- âœ… BibliothÃ¨que exhaustive de patterns FR/EN
- âœ… Normalisation stricte avec validation
- âœ… Tests unitaires par format (EUR, USD, GBP, kg, g, cm, mm)
- âœ… Evidence tracking pour debug
- âœ… Logging des Ã©checs de normalisation

### Risque 3 : Performance DOM parsing

**Impact :** Latence > 50ms par page  
**ProbabilitÃ© :** Moyenne  
**Mitigations :**
- âœ… linkedom (lÃ©ger, performant)
- âœ… Parse sÃ©lectif (limiter profondeur DOM)
- âœ… Batch processing parallÃ¨le (concurrence: 10-20)
- âœ… Cache normalisation unitÃ©s
- âœ… Profiling rÃ©gulier (Deno.bench)

### Risque 4 : QualitÃ© dataset / annotations

**Impact :** MÃ©triques peu fiables, seuils mal calibrÃ©s  
**ProbabilitÃ© :** Moyenne  
**Mitigations :**
- âœ… Annotations multi-personnes avec accord inter-annotateurs
- âœ… Validation set sÃ©parÃ© du test set
- âœ… Mise Ã  jour continue du dataset
- âœ… Ã‰quilibrage classes (50/50 produit/non-produit)
- âœ… Revue manuelle des erreurs de classification

### Risque 5 : Faux positifs (pages non-produit classÃ©es produit)

**Impact :** DÃ©gradation confiance utilisateurs  
**ProbabilitÃ© :** Faible  
**Mitigations :**
- âœ… Seuil conservateur (favoriser prÃ©cision > rappel)
- âœ… Poids Ã©levÃ© pour features structurelles (JSON-LD)
- âœ… Validation multi-critÃ¨res (prix + rÃ©fÃ©rence + images)
- âœ… Score de confiance explicite dans rÃ©sultat

### Risque 6 : RÃ©gression lors des Ã©volutions

**Impact :** Baisse mÃ©triques aprÃ¨s changement code  
**ProbabilitÃ© :** Moyenne  
**Mitigations :**
- âœ… Suite de tests complÃ¨te (â‰¥100 tests)
- âœ… Tests d'intÃ©gration sur dataset complet
- âœ… CI/CD avec gate sur mÃ©triques minimales
- âœ… Benchmarks automatiques avant/aprÃ¨s

---

## Livrables

### Code

```
src/
â”œâ”€â”€ html/
â”‚   â”œâ”€â”€ parser.ts
â”‚   â”œâ”€â”€ content_extractor.ts
â”‚   â”œâ”€â”€ dom_utils.ts
â”‚   â”œâ”€â”€ parser_types.ts
â”‚   â””â”€â”€ parser_test.ts
â”‚
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ product_extractor.ts      # Orchestration
â”‚   â”œâ”€â”€ schema_parser.ts           # JSON-LD, microdata, OG
â”‚   â”œâ”€â”€ pattern_matcher.ts         # Regex patterns
â”‚   â”œâ”€â”€ semantic_extractor.ts      # Tables, listes
â”‚   â”œâ”€â”€ context_extractor.ts       # ProximitÃ© textuelle
â”‚   â”œâ”€â”€ normalizer.ts              # SI, ISO 4217
â”‚   â”œâ”€â”€ fusion.ts                  # Multi-source merge
â”‚   â”œâ”€â”€ patterns.ts                # BibliothÃ¨que patterns
â”‚   â”œâ”€â”€ extraction_types.ts
â”‚   â””â”€â”€ extraction_test.ts
â”‚
â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ features.ts                # Feature engineering
â”‚   â”œâ”€â”€ rule_classifier.ts         # RÃ¨gles pondÃ©rÃ©es
â”‚   â”œâ”€â”€ scoring.ts                 # Scoring dÃ©taillÃ©
â”‚   â”œâ”€â”€ ml_classifier.ts           # ML (Sprint 4)
â”‚   â”œâ”€â”€ calibration.ts             # Calibration seuils
â”‚   â”œâ”€â”€ classification_types.ts
â”‚   â””â”€â”€ classification_test.ts
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ analyzer.ts                # Pipeline principal
â”‚   â”œâ”€â”€ batch_processor.ts         # ParallÃ©lisation
â”‚   â”œâ”€â”€ formatters.ts              # JSON, CSV, Markdown
â”‚   â”œâ”€â”€ reporters.ts               # Rapports mÃ©triques
â”‚   â”œâ”€â”€ analyzer_types.ts
â”‚   â””â”€â”€ analyzer_test.ts
â”‚
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ analyze.ts                 # CLI principal
â”‚   â”œâ”€â”€ commands.ts                # Sous-commandes
â”‚   â”œâ”€â”€ config.ts
â”‚   â””â”€â”€ output.ts
â”‚
â””â”€â”€ text/ (amÃ©liorÃ©)
    â”œâ”€â”€ tokenize.ts                # + digits, n-grams
    â””â”€â”€ stopwords_fr.ts            # Nouveau
```

### Tests

```
tests/
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ full_pipeline_test.ts      # Pipeline bout-en-bout
â”‚   â”œâ”€â”€ dataset_analysis_test.ts   # Test sur dataset complet
â”‚   â””â”€â”€ regression_test.ts         # Non-rÃ©gression
â”‚
â””â”€â”€ benchmarks/
    â”œâ”€â”€ classification_metrics.ts  # MÃ©triques classification
    â”œâ”€â”€ extraction_precision.ts    # MÃ©triques extraction
    â””â”€â”€ performance_bench.ts       # Benchmarks perf
```

### Documentation

```
documentations/
â”œâ”€â”€ USER_GUIDE.md                  # Guide utilisateur CLI
â”œâ”€â”€ API_REFERENCE.md               # Documentation API publique
â”‚
â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ CLASSIFICATION_GUIDE.md    # Guide classification
â”‚   â”œâ”€â”€ FEATURES_REFERENCE.md      # DÃ©tail features
â”‚   â””â”€â”€ CALIBRATION_GUIDE.md       # Calibration seuils
â”‚
â”œâ”€â”€ extraction/
â”‚   â”œâ”€â”€ EXTRACTION_GUIDE.md        # Guide extraction
â”‚   â”œâ”€â”€ PATTERNS_REFERENCE.md      # Catalogue patterns
â”‚   â”œâ”€â”€ SCHEMA_SUPPORT.md          # Standards supportÃ©s
â”‚   â””â”€â”€ NORMALIZATION.md           # Normalisation unitÃ©s
â”‚
â””â”€â”€ pipeline/
    â”œâ”€â”€ PIPELINE_GUIDE.md          # Architecture pipeline
    â””â”€â”€ PERFORMANCE_TUNING.md      # Optimisation perf
```

### Outils

```
tools/
â”œâ”€â”€ dataset_annotator.ts           # Annotation assistÃ©e
â”œâ”€â”€ metrics_reporter.ts            # GÃ©nÃ©ration rapports
â”œâ”€â”€ calibration_tool.ts            # Calibration interactive
â””â”€â”€ validation_dashboard.ts        # Dashboard mÃ©triques
```

### Datasets

```
dataset/
â”œâ”€â”€ pieceoccasion-1.html          # âœ… Existant
â”œâ”€â”€ pieceoccasion-2.html          # âœ… Existant
â”œâ”€â”€ zero-motorcycles-1.html       # âœ… Existant
â”œâ”€â”€ google-1.html                 # âœ… Existant
â”œâ”€â”€ youtube-1.html                # âœ… Existant
â”œâ”€â”€ vehiculeselectriques-forum-1.html # âœ… Existant
â”œâ”€â”€ labels.json                   # NOUVEAU - Annotations
â””â”€â”€ ground_truth.json             # NOUVEAU - Valeurs attendues
```

---

## Stack technique

### Runtime & Langage
- **Deno 1.x** avec TypeScript strict
- Modules natifs Deno (fs, path, testing)

### Parsing HTML
- **linkedom** - Parser DOM lÃ©ger pour Deno
- Support sÃ©lecteurs CSS complets
- Extraction JSON-LD, microdata, Open Graph

### Tests
- **Deno test** natif
- **@std/assert** pour assertions
- **Deno.bench** pour benchmarks perf

### Formats de sortie
- **JSON** (structurÃ©)
- **CSV** (batch analysis)
- **Markdown** (rapports lisibles)
- **Texte** (console)

### ML (Optionnel - Sprint 4)
- **RÃ©gression logistique from scratch** (prÃ©fÃ©rÃ©)
- Alternative: TensorFlow.js ou ml-regression

### DÃ©pendances

```json
{
  "imports": {
    "@std/assert": "jsr:@std/assert@^1",
    "@std/path": "jsr:@std/path@^1",
    "@std/fs": "jsr:@std/fs@^1",
    "linkedom": "npm:linkedom@^0.16"
  }
}
```

---

## Commandes utiles

```bash
# Tests complets
deno test --allow-read

# Tests avec couverture
deno test --allow-read --coverage=coverage/

# Tests d'un module spÃ©cifique
deno test --allow-read src/extraction/

# Benchmarks performance
deno bench --allow-read

# Analyse d'une page
deno run -A cli/analyze.ts --file dataset/pieceoccasion-1.html --format json

# Analyse batch du dataset
deno run -A cli/analyze.ts --dir dataset/ --format csv --out results.csv

# Classification uniquement (plus rapide)
deno run -A cli/analyze.ts --dir dataset/ --classify-only

# GÃ©nÃ©ration rapport mÃ©triques
deno run -A cli/analyze.ts --dir dataset/ --ground-truth dataset/labels.json --metrics-report

# Calibration seuils
deno run -A tools/calibration_tool.ts --dataset dataset/ --labels dataset/labels.json

# Format code
deno fmt

# Lint code
deno lint
```

---

## Prochaines Ã©tapes immÃ©diates

### 1. Validation du plan âœ…
- [x] Relecture du plan final
- [ ] Feedback et ajustements
- [ ] Validation des prioritÃ©s

### 2. Setup Sprint 0 (Jour 1)
- [ ] CrÃ©er structure de dossiers complÃ¨te
- [ ] Ajouter linkedom dans `deno.json`
- [ ] CrÃ©er fichiers de types (`*_types.ts`)
- [ ] Valider compilation

### 3. DÃ©marrage Sprint 1 (Jours 2-4)
- [ ] ImplÃ©menter `src/html/parser.ts` (wrapper linkedom)
- [ ] ImplÃ©menter `src/extraction/schema_parser.ts` (JSON-LD)
- [ ] ImplÃ©menter `src/extraction/patterns.ts` (regex prix EUR)
- [ ] ImplÃ©menter `src/extraction/normalizer.ts` (prix â†’ centimes)
- [ ] Tests sur `pieceoccasion-1.html`

### 4. Validation continue
- [ ] Tests unitaires Ã  chaque commit
- [ ] Validation mÃ©triques aprÃ¨s chaque sprint
- [ ] Documentation Ã  jour

---

## Annexes

### A. Exemples de donnÃ©es extraites attendues

**pieceoccasion-1.html (Sprint 1) :**
```json
{
  "name": "Compresseur air conditionnÃ© pour PEUGEOT 307",
  "reference": "23572714",
  "brand": "PEUGEOT",
  "price": {
    "amount": 12000,
    "currency": "EUR",
    "originalValue": "120.00 â‚¬",
    "confidence": 0.95
  },
  "condition": "used",
  "availability": "in_stock",
  "extractionMethods": ["jsonld", "opengraph", "pattern"],
  "confidence": 0.92
}
```

**pieceoccasion-1.html (Sprint 3, complet) :**
```json
{
  "name": "Compresseur air conditionnÃ© pour PEUGEOT 307",
  "reference": "23572714",
  "brand": "PEUGEOT",
  "model": "307",
  "category": "PiÃ¨ces dÃ©tachÃ©es",
  "price": {
    "amount": 12000,
    "currency": "EUR",
    "originalValue": "120.00 â‚¬",
    "confidence": 0.95
  },
  "weight": {
    "value": 2500,
    "unit": "g",
    "originalValue": "2.5 kg",
    "originalUnit": "kg"
  },
  "availability": "in_stock",
  "condition": "used",
  "images": [
    {
      "url": "https://example.com/product.jpg",
      "width": 800,
      "height": 600,
      "isPrimary": true
    }
  ],
  "extractionMethods": ["jsonld", "opengraph", "pattern", "context", "semantic"],
  "confidence": 0.92
}
```

**RÃ©sultat analyse complÃ¨te :**
```json
{
  "classification": {
    "isProductPage": true,
    "confidence": 0.89,
    "score": 7.8,
    "reasons": [
      "âœ“ JSON-LD Product dÃ©tectÃ©",
      "âœ“ Prix trouvÃ©: 120.00 EUR",
      "âœ“ RÃ©fÃ©rence produit: 23572714",
      "âœ“ Tableau de spÃ©cifications prÃ©sent",
      "âœ“ Images haute rÃ©solution: 3",
      "âš  Pas de bouton 'Ajouter au panier'"
    ],
    "features": { "..." }
  },
  "productData": { "..." },
  "evidence": [
    {
      "field": "price",
      "value": { "amount": 12000, "currency": "EUR" },
      "source": "jsonld",
      "confidence": 0.95,
      "location": "script[type='application/ld+json']"
    },
    {
      "field": "reference",
      "value": "23572714",
      "source": "opengraph",
      "confidence": 0.90,
      "location": "meta[property='product:retailer_item_id']"
    }
  ],
  "textAnalysis": {
    "wordCount": 487,
    "topTerms": [["compresseur", 0.08], ["peugeot", 0.06], ...],
    "language": "fr"
  },
  "metadata": {
    "title": "Compresseur air conditionnÃ© PEUGEOT 307 - PieceOccasion.fr",
    "language": "fr"
  },
  "processingTime": 12.5,
  "stepsCompleted": ["parsing", "normalization", "features", "classification", "extraction", "tfidf"]
}
```

### B. Exemples de commandes CLI

```bash
# Analyse simple
deno run -A cli/analyze.ts --file dataset/pieceoccasion-1.html

# Batch avec rapport Markdown
deno run -A cli/analyze.ts --dir dataset/ --format markdown --out report.md

# Export CSV pour analyse Excel
deno run -A cli/analyze.ts --dir dataset/ --format csv --out results.csv

# Avec options classification personnalisÃ©es
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --threshold 6.0 \
  --structural-weight 0.6 \
  --textual-weight 0.3 \
  --semantic-weight 0.1

# Mode debug complet
deno run -A cli/analyze.ts \
  --file dataset/pieceoccasion-1.html \
  --verbose \
  --include-features \
  --include-evidence \
  --format json \
  --pretty

# Ã‰valuation avec ground truth
deno run -A cli/analyze.ts \
  --dir dataset/ \
  --ground-truth dataset/labels.json \
  --metrics-report \
  --out metrics.json
```

---

**Fin du plan de dÃ©veloppement final**

*Version consolidÃ©e - PrÃªt pour implÃ©mentation*  
*Date: 4 octobre 2025*
